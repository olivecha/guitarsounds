<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>guitarsounds API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>guitarsounds</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import librosa
import librosa.display
from soundfile import write
import IPython.display as ipd
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import os
from noisereduce.noisereducev1 import reduce_noise
import scipy
import scipy.optimize
import scipy.integrate
import scipy.interpolate
from scipy import signal as sig
from guitarsounds_parameters import sound_parameters
import guitarsounds_utils as utils
from tabulate import tabulate

&#34;&#34;&#34;
Getting the sound parameters from the guitarsounds_parameters.py file
&#34;&#34;&#34;
SP = sound_parameters()

&#34;&#34;&#34;
Classes
&#34;&#34;&#34;

class SoundPack(object):
    &#34;&#34;&#34;
    A class to store and analyse multiple sounds
    Some methods are only available for the case with two sounds
    &#34;&#34;&#34;

    def __init__(self, *sounds, names=None, fundamentals=None, SoundParams=None, equalize_time=True):
        &#34;&#34;&#34;
        The SoundPack can be instantiated from existing Sound class instances, either in a list or as
        multiple arguments

        The class can also handle the creation of Sound class instances if the arguments are filenames,
        either a list or multiple arguments.

        If the number of Sound contained is equal to two, the SoundPack will be &#39;dual&#39; and the associated methods
        will be available

        If it contains multiple sounds the SoundPack will be multiple and a reduced number of methods will work

        A list of names as strings and fundamental frequencies can be specified when creating the SoundPack

        If equalize_time is set to False, the contained sounds will not be trimmed to the same length.

        Examples :
        ```
        Sound_Test = SoundPack(&#39;sounds/test1.wav&#39;, &#39;sounds/test2.wav&#39;, names=[&#39;A&#39;, &#39;B&#39;], fundamentals = [134, 134])

        sounds = [sound1, sound2, sound3, sound4, sound5] # instances of the Sound class
        large_Test = SoundPack(sounds, names=[&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;])
        ```
        &#34;&#34;&#34;
        # create a copy of the sound parameters
        if SoundParams is None:
            self.SP = SP
        else:
            self.SP = SoundParams

        # Check if the sounds argument is a list
        if type(sounds[0]) is list:
            sounds = sounds[0]  # unpack the list

        # Check for special case
        if len(sounds) == 2:
            # special case to compare two sounds
            self.kind = &#39;dual&#39;

        elif len(sounds) &gt; 1:
            # general case for multiple sounds
            self.kind = &#39;multiple&#39;

        if type(sounds[0]) is str:
            self.sounds_from_files(sounds, names=names, fundamentals=fundamentals)

        else:
            self.sounds = sounds
            if names is None:
                names = [str(n) for n in np.arange(1, len(sounds)+1)]
                for sound, n in zip(self.sounds, names):
                    sound.name = n

        if equalize_time:
            self.equalize_time()

    def sounds_from_files(self, sound_files, names=None, fundamentals=None):
        &#34;&#34;&#34;
        Create Sound class instances and assign them to the SoundPack from a list of files
        :param sound_files: sound filenames
        :param names: sound names
        :param fundamentals: user specified fundamental frequencies
        :return: None
        &#34;&#34;&#34;
        # Make the default name list from sound filenames if none is supplied
        if (names is None) or (len(names) != len(sound_files)):
            names = [file[:-4] for file in sound_files]  # remove the .wav

        # If the fundamentals are not supplied or mismatch in number None is used
        if (fundamentals is None) or (len(fundamentals) != len(sound_files)):
            fundamentals = len(sound_files) * [None]

        # Create Sound instances from files
        self.sounds = []
        for file, name, fundamental in zip(sound_files, names, fundamentals):
            self.sounds.append(Sound(file, name=name, fundamental=fundamental,
                                     SoundParams=self.SP).condition(return_self=True))

    def equalize_time(self):
        &#34;&#34;&#34;
        Trim the sounds so that they all have the length of the shortest sound, trimming is done at the end.
        :return: None
        &#34;&#34;&#34;
        trim_index = np.min([len(sound.signal.signal) for sound in self.sounds])
        trimmed_sounds = []
        for sound in self.sounds:
            new_sound = sound
            new_sound.signal = new_sound.signal.trim_time(trim_index / sound.signal.sr)
            new_sound.bin_divide()
            trimmed_sounds.append(new_sound)
        self.sounds = trimmed_sounds

    def normalize(self):
        &#34;&#34;&#34;
        Normalize all the signals in the SoundPack and returns a normaized
        instance of itself
        :return: SoundPack with normalized signals
        &#34;&#34;&#34;
        new_sounds = []
        names = [sound.name for sound in self.sounds]
        fundamentals = [sound.fundamental for sound in self.sounds]
        for sound in self.sounds:
            sound.signal = sound.signal.normalize()
            new_sounds.append(sound)

        return SoundPack(new_sounds, names=names, fundamentals=fundamentals, SoundParams=self.SP, equalize_time=False)

    &#34;&#34;&#34;
    Methods for all SoundPacks
    &#34;&#34;&#34;

    def plot(self, kind, **kwargs):
        &#34;&#34;&#34;
        __ Multiple SoundPack Method __
        Plots a specific signal.plot for all sounds on the same figure
        Ex : compare_plot(&#39;fft&#39;) plots the fft of all sounds on a single figure
        The color argument is set to none so that the plots have different colors

        :param kind: Attribute passed to the `signal.plot()` method
        :param kwargs: key words arguments to pass to the `signal.plot()` method
        :return: None
        &#34;&#34;&#34;
        for sound in self.sounds:
            kwargs[&#39;label&#39;] = sound.name
            kwargs[&#39;color&#39;] = None
            sound.signal.plot(kind, **kwargs)

        plt.legend()

    def compare_plot(self, kind, **kwargs):
        &#34;&#34;&#34;
        __ Multiple SoundPack Method __
        Draws the same kind of plot on a different axis for each sound
        Example : `SoundPack.compare_plot(&#39;peaks&#39;)` with 4 Sounds will plot a figure with 4 axes, with each
        a different &#39;peak&#39; plot.

        :param kind: kind argument passed to `Signal.plot()`
        :param kwargs: key word arguments passed to Signal.plot()
        :return: None
        &#34;&#34;&#34;
        # if a dual SoundPack : only plot two big plots
        if self.kind == &#39;dual&#39;:
            fig, axs = plt.subplots(1, 2, figsize=(12, 6))
            for sound, ax in zip(self.sounds, axs):
                plt.sca(ax)
                kwargs[&#39;label&#39;] = sound.name
                sound.signal.plot(kind, **kwargs)

        # If a multiple SoundPack : plot on a grid of axes
        elif self.kind == &#39;multiple&#39;:

            # find the n, m values for the subplots line and columns
            n = len(self.sounds)
            if n // 4 &gt;= 10:
                # a lot of sounds
                cols = 4
            elif n // 3 &gt;= 10:
                # many sounds
                cols = 3
            elif n // 2 &lt;= 4:
                # a few sounds
                cols = 2

            remainder = n % cols
            if remainder == 0:
                rows = n // cols
            else:
                rows = n // cols + 1

            fig, axs = plt.subplots(rows, cols, figsize=(12, 4*rows))
            axs = axs.reshape(-1)
            for sound, ax in zip(self.sounds, axs):
                plt.sca(ax)
                sound.signal.plot(kind, **kwargs)
                title = ax.get_title()
                title = sound.name + &#39; &#39; + title
                ax.set_title(title)

            if remainder != 0:
                for ax in axs[-(cols - remainder):]:
                    ax.set_axis_off()

            plt.tight_layout()

    def freq_bin_plot(self, fbin=&#39;all&#39;):
        &#34;&#34;&#34;
        __ Multiple SoundPack Method __
        A function to compare signals decomposed frequency wise in the time domain on a logarithm scale.
        The methods plots all the sounds and plots their frequency bins according to the frequency bin argument fbin.

        Example : SoundPack.freq_bin_plot(fbin=&#39;mid&#39;) will plot the log-scale envelop of the &#39;mid&#39; signal of every
        sound in the SoundPack

        :param fbin: frequency bins to compare, Supported arguments are :
        &#39;all&#39;, &#39;bass&#39;, &#39;mid&#39;, &#39;highmid&#39;, &#39;uppermid&#39;, &#39;presence&#39;, &#39;brillance&#39;
        :return: None
        &#34;&#34;&#34;

        if fbin == &#39;all&#39;:
            # Create one plot per bin
            for key in [*list(self.SP.bins.__dict__.keys())[1:], &#39;brillance&#39;]:
                plt.figure(figsize=(10, 8))
                # plot every sound for a frequency bin
                norm_factors = np.array([son.bins[key].normalize().norm_factor for son in self.sounds])
                for i, son in enumerate(self.sounds):
                    lab = &#39; &#39; + key + &#39; : &#39; + str(int(son.bins[key].range[0])) + &#39; - &#39; + str(
                        int(son.bins[key].range[1])) + &#39; Hz&#39;
                    son.bins[key].normalize().plot(&#39;log envelop&#39;, label=(str(i + 1) + &#39;. &#39; + son.name + lab))
                plt.xscale(&#39;log&#39;)
                plt.legend()
                title1 = &#39;Normalisation Factor 1 : &#39; + str(np.around(norm_factors[0], 0)) + &#39;x, &#39;
                title2 = &#39;Normalisation Factor 2 : &#39; + str(np.around(norm_factors[1], 0)) + &#39;x&#39;
                plt.title(title1 + title2)

        elif fbin in [*list(SP.bins.__dict__.keys())[1:], &#39;brillance&#39;]:
            plt.figure(figsize=(10, 8))
            # Plot every envelop for a single frequency bin
            norm_factors = np.array([son.bins[fbin].normalize().norm_factor for son in self.sounds])
            for i, son in enumerate(self.sounds):
                lab = &#39; &#39; + fbin + &#39; : &#39; + str(int(son.bins[fbin].range[0])) + &#39; - &#39; + str(
                    int(son.bins[fbin].range[1])) + &#39; Hz&#39;
                son.bins[fbin].normalize().plot(&#39;log envelop&#39;, label=(str(i + 1) + &#39;. &#39; + son.name + lab))
            plt.xscale(&#39;log&#39;)
            plt.legend()
            title1 = &#39;Normalisation Factor 1 : &#39; + str(np.around(norm_factors[0], 0)) + &#39;x\n&#39;
            title2 = &#39;Normalisation Factor 2 : &#39; + str(np.around(norm_factors[1], 0)) + &#39;x&#39;
            plt.title(title1 + title2)

        else:
            print(&#39;invalid frequency bin&#39;)

    def combine_envelop(self, kind=&#39;signal&#39;, difference_factor=1, show_sounds=True, show_rejects=True, **kwargs):
        &#34;&#34;&#34;
        __ Multiple SoundPack Method __
        Combines the envelops of the Sounds contained in the SoundPack, Sounds having a too large difference factor
        from the average are rejected.

        :param kind: wich signal to use from :
        &#39;signal&#39;, &#39;bass&#39;, &#39;mid&#39;, &#39;highmid&#39;, &#39;uppermid&#39;, &#39;presence&#39;, &#39;brillance&#39;
        :param difference_factor: threshold to reject a sound from the combinaison, can be adjusted to reject
        or include more sounds.
        :param show_sounds: If True all the included Sounds are shown on the plot
        :param show_rejects: If True all the rejected Sounds are shown on the plot
        :param kwargs: Key word arguments to pass to the envelop plot.
        :return: None
        &#34;&#34;&#34;
        sounds = self.sounds
        sample_number = np.min([len(s1.signal.log_envelop()[0]) for s1 in sounds])

        if kind == &#39;signal&#39;:
            log_envelops = np.stack([s1.signal.normalize().log_envelop()[0][:sample_number] for s1 in sounds])
        elif kind in SP.bins.__dict__.keys():
            log_envelops = np.stack([s1.bins[kind].normalize().log_envelop()[0][:sample_number] for s1 in sounds])
        else:
            print(&#39;Wrong kind&#39;)

        average_log_envelop = np.mean(log_envelops, axis=0)
        means = np.tile(average_log_envelop, (len(sounds), 1))
        diffs = np.sum(np.abs(means - log_envelops), axis=1)
        diff = np.mean(diffs) * difference_factor

        good_sounds = np.array(sounds)[diffs &lt; diff]
        rejected_sounds = np.array(sounds)[diffs &gt; diff]
        average_log_envelop = np.mean(log_envelops[diffs &lt; diff], axis=0)
        norm_factors = np.array([s1.signal.normalize().norm_factor for s1 in good_sounds])

        if kind == &#39;signal&#39;:
            if show_sounds:
                for s1 in good_sounds[:-1]:
                    s1.signal.normalize().plot(kind=&#39;log envelop&#39;, alpha=0.2, color=&#39;k&#39;)
                sounds[-1].signal.normalize().plot(kind=&#39;log envelop&#39;, alpha=0.2, color=&#39;k&#39;, label=&#39;sounds&#39;)

            if show_rejects:
                if len(rejected_sounds) &gt; 1:
                    for s1 in rejected_sounds[:-1]:
                        s1.signal.normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;)
                    rejected_sounds[-1].signal.normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;,
                                                                label=&#39;rejected sounds&#39;)
                if len(rejected_sounds) == 1:
                    rejected_sounds[0].signal.normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;,
                                                               label=&#39;rejected sounds&#39;)
            if len(good_sounds) &gt; 0:
                if &#39;label&#39; in kwargs.keys():
                    plt.plot(good_sounds[0].signal.log_envelop()[1][:len(average_log_envelop)], average_log_envelop,
                             **kwargs)
                else:
                    plt.plot(good_sounds[0].signal.log_envelop()[1][:len(average_log_envelop)], average_log_envelop,
                             label=&#39;average&#39;, color=&#39;k&#39;, **kwargs)

        else:
            if show_sounds:
                for s1 in good_sounds[:-1]:
                    s1.bins[kind].normalize().plot(kind=&#39;log envelop&#39;, alpha=0.2, color=&#39;k&#39;)
                sounds[-1].bins[kind].normalize().plot(kind=&#39;log envelop&#39;, alpha=0.2, color=&#39;k&#39;, label=&#39;sounds&#39;)

            if show_rejects:
                if len(rejected_sounds) &gt; 1:
                    for s2 in rejected_sounds[:-1]:
                        s2.bins[kind].normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;)
                    rejected_sounds[-1].bins[kind].normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;,
                                                                    label=&#39;rejected sounds&#39;)
                if len(rejected_sounds) == 1:
                    rejected_sounds.bins[kind].normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;,
                                                                label=&#39;rejected sounds&#39;)

            plt.plot(good_sounds[0].signal.log_envelop()[1][:sample_number], average_log_envelop, color=&#39;k&#39;, **kwargs)

        plt.xlabel(&#39;time (s)&#39;)
        plt.ylabel(&#39;Amplitude&#39;)
        plt.legend()
        plt.xscale(&#39;log&#39;)
        print(&#39;Number of rejected sounds : &#39; + str(len(rejected_sounds)))
        print(&#39;Number of sounds included : &#39; + str(len(good_sounds)))
        print(&#39;Maximum normalisation factor : &#39; + str(np.around(np.max(norm_factors), 0)) + &#39;x&#39;)
        print(&#39;Minimum normalisation factor : &#39; + str(np.around(np.min(norm_factors), 0)) + &#39;x&#39;)

    def fundamentals(self):
        &#34;&#34;&#34;
        __ Multiple Soundpack Method __
        Displays the fundamentals of every sound in the SoundPack
        :return: None
        &#34;&#34;&#34;
        print(tabulate([[sound.name, np.around(sound.fundamental, 1)] for sound in self.sounds],
                       headers=[&#39;Name&#39;, &#39;Fundamental (Hz)&#39;]))

    &#34;&#34;&#34;
    Methods for dual SoundPacks
    &#34;&#34;&#34;

    def compare_peaks(self):
        &#34;&#34;&#34;
        __ Dual SoundPack Method __
        Compares the peaks in the Fourier Transform of two Sounds,
        the peak with the highest difference is highlighted
        :return: None
        &#34;&#34;&#34;
        if self.kind == &#39;dual&#39;:
            son1 = self.sounds[0]
            son2 = self.sounds[1]
            index1 = np.where(son1.signal.fft_frequencies() &gt; self.SP.general.fft_range.value)[0][0]
            index2 = np.where(son2.signal.fft_frequencies() &gt; self.SP.general.fft_range.value)[0][0]

            # Get the peak data from the sounds
            peaks1 = son1.signal.peaks()
            peaks2 = son2.signal.peaks()
            freq1 = son1.signal.fft_frequencies()[:index1]
            freq2 = son2.signal.fft_frequencies()[:index2]
            fft1 = son1.signal.fft()[:index1]
            fft2 = son2.signal.fft()[:index2]

            peak_distance1 = np.mean([freq1[peaks1[i]] - freq1[peaks1[i + 1]] for i in range(len(peaks1) - 1)]) / 4
            peak_distance2 = np.mean([freq2[peaks2[i]] - freq2[peaks2[i + 1]] for i in range(len(peaks2) - 1)]) / 4
            peak_distance = np.abs(np.mean([peak_distance1, peak_distance2]))

            # Align  the two peak vectors
            new_peaks1 = []
            new_peaks2 = []
            for peak1 in peaks1:
                for peak2 in peaks2:
                    if np.abs(freq1[peak1] - freq2[peak2]) &lt; peak_distance:
                        new_peaks1.append(peak1)
                        new_peaks2.append(peak2)
            new_peaks1 = np.unique(np.array(new_peaks1))
            new_peaks2 = np.unique(np.array(new_peaks2))

            different_peaks1 = []
            different_peaks2 = []
            difference_threshold = 0.5
            while len(different_peaks1) &lt; 1:
                for peak1, peak2 in zip(new_peaks1, new_peaks2):
                    if np.abs(fft1[peak1] - fft2[peak2]) &gt; difference_threshold:
                        different_peaks1.append(peak1)
                        different_peaks2.append(peak2)
                difference_threshold -= 0.01

            # Plot the output
            plt.figure(figsize=(10, 8))
            plt.yscale(&#39;symlog&#39;, linthresh=10e-1)

            # Sound 1
            plt.plot(freq1, fft1, color=&#39;#919191&#39;, label=son1.name)
            plt.scatter(freq1[new_peaks1], fft1[new_peaks1], color=&#39;b&#39;, label=&#39;peaks&#39;)
            plt.scatter(freq1[different_peaks1], fft1[different_peaks1], color=&#39;g&#39;, label=&#39;diff peaks&#39;)
            annotation_string = &#39;Peaks with &#39; + str(np.around(difference_threshold, 1)) + &#39; difference&#39;
            plt.annotate(annotation_string, (freq1[different_peaks1[0]] + peak_distance / 2, fft1[different_peaks1[0]]))

            # Sound2
            plt.plot(freq2, -fft2, color=&#39;#3d3d3d&#39;, label=son2.name)
            plt.scatter(freq2[new_peaks2], -fft2[new_peaks2], color=&#39;b&#39;)
            plt.scatter(freq2[different_peaks2], -fft2[different_peaks2], color=&#39;g&#39;)

            plt.title(&#39;Fourier Transform Peak Analysis&#39;)
            plt.legend()
        else:
            print(&#39;Unsupported for multiple sounds SoundPacks&#39;)

    def fft_mirror(self):
        &#34;&#34;&#34;
        __ Dual SoundPack Method __
        Plot the fourier transforms of two sounds on the y and -y axes to compare them.
        :return: None
        &#34;&#34;&#34;
        if self.kind == &#39;dual&#39;:
            son1 = self.sounds[0]
            son2 = self.sounds[1]
            index = np.where(son1.signal.fft_frequencies() &gt; SP.general.fft_range.value)[0][0]

            plt.figure(figsize=(10, 8))
            plt.yscale(&#39;symlog&#39;)
            plt.grid(&#39;on&#39;)
            plt.plot(son1.signal.fft_frequencies()[:index], son1.signal.fft()[:index], label=son1.name)
            plt.plot(son2.signal.fft_frequencies()[:index], -son2.signal.fft()[:index], label=son2.name)
            plt.xlabel(&#39;Fréquence (Hz)&#39;)
            plt.ylabel(&#39;Amplitude&#39;)
            plt.legend()
            plt.show()
        else:
            print(&#39;Unsupported for multiple sounds SoundPacks&#39;)

    def fft_diff(self, fraction=3, ticks=None):
        &#34;&#34;&#34;
        __ Dual SoundPack Method __
        Compare the Fourier Transform of two sounds by computing the differences of the octave bins heights.
        The two FTs are superimposed on the first plot to show differences
        The difference between the two FTs is plotted on the second plot

        :param fraction: octave fraction value used to compute the frequency bins A higher number will show
        a more precise comparison, but conclusions may be harder to draw.
        :param ticks:  If True the frequency bins intervals are used as X axis ticks
        :return: None
        &#34;&#34;&#34;
        if self.kind == &#39;dual&#39;:
            # Separate the sounds
            son1 = self.sounds[0]
            son2 = self.sounds[1]

            # Compute plotting bins
            x_values = utils.octave_values(fraction)
            hist_bins = utils.octave_histogram(fraction)
            bar_widths = np.array([hist_bins[i + 1] - hist_bins[i] for i in range(0, len(hist_bins) - 1)])

            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
            plot1 = ax1.hist(son1.signal.fft_bins(), utils.octave_histogram(fraction), color=&#39;blue&#39;, alpha=0.6,
                             label=son1.name)
            plot2 = ax1.hist(son2.signal.fft_bins(), utils.octave_histogram(fraction), color=&#39;orange&#39;, alpha=0.6,
                             label=son2.name)
            ax1.set_title(&#39;Histogramme de la FT des deux sons&#39;)
            ax1.set_xscale(&#39;log&#39;)
            ax1.set_xlabel(&#39;Fréquence (Hz)&#39;)
            ax1.set_ylabel(&#39;Amplitude&#39;)
            ax1.grid(&#39;on&#39;)
            ax1.legend()

            diff = plot1[0] - plot2[0]
            n_index = np.where(diff &lt;= 0)[0]
            p_index = np.where(diff &gt;= 0)[0]

            # Negative difference corresponding to sound 2
            ax2.bar(x_values[n_index], diff[n_index], width=bar_widths[n_index], color=&#39;orange&#39;, alpha=0.6)
            # Positive difference corresponding to sound1
            ax2.bar(x_values[p_index], diff[p_index], width=bar_widths[p_index], color=&#39;blue&#39;, alpha=0.6)
            ax2.set_title(&#39;Différence Son 1 - Son 2&#39;)
            ax2.set_xscale(&#39;log&#39;)
            ax2.set_xlabel(&#39;Fréquence (Hz)&#39;)
            ax2.set_ylabel(&#39;&lt;- Son 2 : Son 1 -&gt;&#39;)
            ax2.grid(&#39;on&#39;)

            if ticks == &#39;bins&#39;:
                labels = [label for label in self.SP.bins.__dict__ if label != &#39;name&#39;]
                labels.append(&#39;brillance&#39;)
                x = [param.value for param in self.SP.bins.__dict__.values() if param != &#39;bins&#39;]
                x.append(11250)
                x_formatter = matplotlib.ticker.FixedFormatter(labels)
                x_locator = matplotlib.ticker.FixedLocator(x)
                ax1.xaxis.set_major_locator(x_locator)
                ax1.xaxis.set_major_formatter(x_formatter)
                ax1.tick_params(axis=&#34;x&#34;, labelrotation=90)
                ax2.xaxis.set_major_locator(x_locator)
                ax2.xaxis.set_major_formatter(x_formatter)
                ax2.tick_params(axis=&#34;x&#34;, labelrotation=90)


        else:
            print(&#39;Unsupported for multiple sounds SoundPacks&#39;)

    def coherence_plot(self):
        &#34;&#34;&#34;
        __ Dual SoundPack Method __
        computes and plots the coherence between the time signal of two Sounds
        :return: None
        &#34;&#34;&#34;
        if self.kind == &#39;dual&#39;:
            f, C = sig.coherence(self.sounds[0].signal.signal, self.sounds[1].signal.signal, self.sounds[0].signal.sr)
            plt.plot(f, C, color=&#39;b&#39;)
            plt.yscale(&#39;log&#39;)
            plt.xlabel(&#39;Fréquence (Hz)&#39;)
            plt.ylabel(&#39;Coherence [0, 1]&#39;)
            title = &#39;Cohérence entre les sons &#39; + self.sounds[0].name + &#39; et &#39; + self.sounds[1].name
            plt.title(title)
        else:
            print(&#39;Unsupported for multiple sounds SoundPacks&#39;)


class Signal(object):
    &#34;&#34;&#34;
    A Class to do computations on an audio signal.

    The signal is never changed in the class, when transformations are made, a new instance is returned.

    &#34;&#34;&#34;

    def __init__(self, signal, sr, SoundParam, freq_range=None):
        &#34;&#34;&#34; Create a Signal class from a vector of samples and a sample rate&#34;&#34;&#34;
        self.SP = SoundParam
        self.onset = None
        self.signal = signal
        self.sr = sr
        self.range = freq_range
        self.trimmed = None
        self.noise = None

    def time(self):
        &#34;&#34;&#34;
        Returns the time vector associated to the signal
        :return: numpy array corresponding to the time values of the signal samples in seconds
        &#34;&#34;&#34;
        return np.arange(0, len(self.signal) * (1 / self.sr), 1 / self.sr)

    def listen(self):
        &#34;&#34;&#34;Method to listen the sound signal in a Jupyter Notebook&#34;&#34;&#34;
        file = &#39;temp.wav&#39;
        write(file, self.signal, self.sr)
        ipd.display(ipd.Audio(file))
        os.remove(file)

    # noinspection PyUnresolvedReferences
    def plot(self, kind, **kwargs):
        &#34;&#34;&#34;
        General plotting method for the Signal class, supported plots are:

        &#39;signal&#39; :
            Plots the time varying real signal as amplitude vs time.

        &#39;envelop&#39; :
            Plots the envelop of the signal as amplitude vs time.

        &#39;log envelop&#39; :
            Plots the envelop with logarithmic window widths on a logarithmic x axis scale.

        &#39;fft&#39; :
            Plots the Fourier Transform of the Signal.
            If `ticks = &#39;bins&#39;` is supplied in the keyword arguments, the frequency ticks are replaced
            with the frequency bin values

        &#39;fft hist&#39; :
            Plots the octave based Fourier Transform Histogram.
            Both axes are on a log scale.
            If `ticks = &#39;bins&#39;` is supplied in the keyword arguments, the frequency ticks are replaced
            with the frequency bin values

        &#39;peaks&#39; :
            Plots the Fourier Transform of the Signal, with the peaks detected with the `Signal.peaks()` method.
            If `peak_height = True` is supplied in the keyword arguments the computed height threshold is
            shown on the plot.

        &#39;peak damping&#39; :
            Plots the frequency vs damping scatter of the damping ratio computed from the
            Fourier Transform peak shapes. A polynomial curve fit is added to help visualisation.
            Supported key word arguments are :
            `n=5` : The order of the fitted polynomial curve, default is 5,
            if the supplied value is too high, it will be reduced until the number of peaks
            is sufficient to fit the polynomial.

            `inverse=True` : Default value is True, if False, the damping ratio is shown instead
            of its inverse.

            `normalize=False` : Default value is False, if True the damping values are normalized
            from 0 to 1, to help analyze results and compare Sounds.

            `ticks=None` : Default value is None, if `ticks=&#39;bins&#39;` the x axis ticks are replaced with
            frequency bin values.

        &#39;time damping&#39; :
            Shows the signal envelop with the fitted negative exponential curve used to determine the
            time damping ratio of the signal.
        &#34;&#34;&#34;
        illegal_kwargs = [&#39;max_time&#39;, &#39;n&#39;, &#39;ticks&#39;, &#39;normalize&#39;, &#39;inverse&#39;, &#39;peak_height&#39;]
        plot_kwargs = {i: kwargs[i] for i in kwargs if i not in illegal_kwargs}

        if kind == &#39;signal&#39;:

            plt.plot(self.time(), self.signal, alpha=0.6, **plot_kwargs)
            plt.xlabel(&#39;time (s)&#39;)
            plt.ylabel(&#39;amplitude&#39;)

        elif kind == &#39;envelop&#39;:

            plt.plot(self.envelop_time(), self.envelop(), **plot_kwargs)
            plt.xlabel(&#34;time (s)&#34;)
            plt.ylabel(&#34;amplitude&#34;)
            plt.grid(&#39;on&#39;)

        elif kind == &#39;log envelop&#39;:
            log_envelop, log_envelop_time = self.log_envelop()
            if (&#39;max_time&#39; in kwargs.keys()) and (kwargs[&#39;max_time&#39;] &lt; log_envelop_time[-1]):
                    max_index = np.nonzero(log_envelop_time &gt;= kwargs[&#39;max_time&#39;])[0][0]
            else:
                max_index = len(log_envelop_time)

            plt.plot(log_envelop_time[:max_index], log_envelop[:max_index], **plot_kwargs)
            plt.xlabel(&#34;time (s)&#34;)
            plt.ylabel(&#34;amplitude&#34;)
            plt.xscale(&#39;log&#39;)
            plt.grid(&#39;on&#39;)

        elif kind == &#39;fft&#39;:
            # find the index corresponding to the fft range
            result = np.where(self.fft_frequencies() &gt;= self.SP.general.fft_range.value)[0]
            if len(result) == 0:
                last_index = -1
            else:
                last_index = result[0]
            plt.plot(self.fft_frequencies()[:last_index], self.fft()[:last_index], **plot_kwargs)
            plt.xlabel(&#34;frequency&#34;),
            plt.ylabel(&#34;amplitude&#34;),
            plt.yscale(&#39;log&#39;)
            plt.grid(&#39;on&#39;)

            if &#39;ticks&#39; in kwargs and kwargs[&#39;ticks&#39;] == &#39;bins&#39;:
                labels = [label for label in self.SP.bins.__dict__ if label != &#39;name&#39;]
                labels.append(&#39;brillance&#39;)
                x = [param.value for param in self.SP.bins.__dict__.values() if param != &#39;bins&#39;]
                x.append(11250)
                x_formatter = matplotlib.ticker.FixedFormatter(labels)
                x_locator = matplotlib.ticker.FixedLocator(x)
                ax = plt.gca()
                ax.xaxis.set_major_locator(x_locator)
                ax.xaxis.set_major_formatter(x_formatter)
                ax.tick_params(axis=&#34;x&#34;, labelrotation=90)

        elif kind == &#39;fft hist&#39;:
            # Histogram of frequency values occurences in octave bins
            plt.hist(self.fft_bins(), utils.octave_histogram(self.SP.general.octave_fraction.value),
                     alpha=0.7, **plot_kwargs)
            plt.xlabel(&#39;Fréquence (Hz)&#39;)
            plt.ylabel(&#39;Amplitude&#39;)
            plt.xscale(&#39;log&#39;)
            plt.yscale(&#39;log&#39;)
            plt.grid(&#39;on&#39;)

            if &#39;ticks&#39; in kwargs and kwargs[&#39;ticks&#39;] == &#39;bins&#39;:
                labels = [label for label in self.SP.bins.__dict__ if label != &#39;name&#39;]
                labels.append(&#39;brillance&#39;)
                x = [param.value for param in self.SP.bins.__dict__.values() if param != &#39;bins&#39;]
                x.append(11250)
                x_formatter = matplotlib.ticker.FixedFormatter(labels)
                x_locator = matplotlib.ticker.FixedLocator(x)
                ax = plt.gca()
                ax.xaxis.set_major_locator(x_locator)
                ax.xaxis.set_major_formatter(x_formatter)
                ax.tick_params(axis=&#34;x&#34;, labelrotation=90)

        elif kind == &#39;peaks&#39;:
            fft_freqs = self.fft_frequencies()
            fft = self.fft()
            max_index = np.where(fft_freqs &gt;= self.SP.general.fft_range.value)[0][0]
            peak_indexes, height = self.peaks(height=True)
            plt.xlabel(&#39;Fréquence (Hz)&#39;)
            plt.ylabel(&#39;Amplitude&#39;)
            plt.yscale(&#39;log&#39;)
            plt.grid(&#39;on&#39;)

            if &#39;color&#39; not in plot_kwargs.keys():
                plot_kwargs[&#39;color&#39;] = &#39;k&#39;
            plt.plot(fft_freqs[:max_index], fft[:max_index], **plot_kwargs)
            plt.scatter(fft_freqs[peak_indexes], fft[peak_indexes], color=&#39;r&#39;)
            if (&#39;peak_height&#39; in kwargs.keys()) and (kwargs[&#39;peak_height&#39;]):
                plt.plot(fft_freqs[:max_index], height, color=&#39;r&#39;)

        elif kind == &#39;peak damping&#39;:
            # Get the damping ration and peak frequencies
            if &#39;inverse&#39; in kwargs.keys() and kwargs[&#39;inverse&#39;] is False:
                zetas = np.array(self.peak_damping())
                ylabel = r&#39;Damping $\zeta$&#39;
            else:
                zetas = 1 / np.array(self.peak_damping())
                ylabel = r&#39;Inverse Damping $1/\zeta$&#39;

            peak_freqs = self.fft_frequencies()[self.peaks()]

            # If a polynomial order is supplied assign it, if not default is 5
            if &#39;n&#39; in kwargs.keys():
                n = kwargs[&#39;n&#39;]
            else:
                n = 5

            # If labels are supplied the default color are used
            if &#39;label&#39; in plot_kwargs:
                plot_kwargs[&#39;color&#39;] = None
                plot2_kwargs = plot_kwargs.copy()
                plot2_kwargs[&#39;label&#39;] = None

            # If not black and red are used
            else:
                plot_kwargs[&#39;color&#39;] = &#39;r&#39;
                plot2_kwargs = plot_kwargs.copy()
                plot2_kwargs[&#39;color&#39;] = &#39;k&#39;

            if &#39;normalize&#39; in kwargs.keys() and kwargs[&#39;normalize&#39;]:
                zetas = np.array(zetas)/np.array(zetas).max()

            plt.scatter(peak_freqs, zetas, **plot_kwargs)
            fun = utils.nth_order_polynomial_fit(n, peak_freqs, zetas)
            freq = np.linspace(peak_freqs[0], peak_freqs[-1], 100)
            plt.plot(freq, fun(freq), **plot2_kwargs)
            plt.grid(&#39;on&#39;)
            plt.title(&#39;Frequency vs Damping Factor with Order &#39; + str(n))
            plt.xlabel(&#39;Frequency (Hz)&#39;)
            plt.ylabel(ylabel)

            if &#39;ticks&#39; in kwargs and kwargs[&#39;ticks&#39;] == &#39;bins&#39;:
                labels = [label for label in self.SP.bins.__dict__ if label != &#39;name&#39;]
                labels.append(&#39;brillance&#39;)
                x = [param.value for param in self.SP.bins.__dict__.values() if param != &#39;bins&#39;]
                x.append(11250)
                x_formatter = matplotlib.ticker.FixedFormatter(labels)
                x_locator = matplotlib.ticker.FixedLocator(x)
                ax = plt.gca()
                ax.xaxis.set_major_locator(x_locator)
                ax.xaxis.set_major_formatter(x_formatter)
                ax.tick_params(axis=&#34;x&#34;, labelrotation=90)

        elif kind == &#39;time damping&#39;:
            # Get the envelop data
            envelop_time = self.normalize().envelop_time()
            envelop = self.normalize().envelop()

            # First point is the maximum because e^-kt is stricly decreasing
            first_index = np.argmax(envelop)

            # The second point is the first point where the signal crosses the lower_threshold line
            second_point_thresh = self.SP.damping.lower_threshold.value

            try:
                second_index = np.flatnonzero(envelop[first_index:] &lt;= second_point_thresh)[0]
            except IndexError:
                second_index = np.flatnonzero(envelop[first_index:] &lt;= second_point_thresh * 2)[0]

            # Function to compute the residual for the exponential curve fit
            def residual_function(zeta_w, t, s):
                return np.exp(zeta_w[0] * t) - s
            zeta_guess = [-0.5]

            result = scipy.optimize.least_squares(residual_function, zeta_guess,
                                                  args=(envelop_time[first_index:second_index],
                                                        envelop[first_index:second_index]))
            # Get the zeta*omega constant
            zeta_omega = result.x[0]

            # Compute the fundamental frequency in radiants of the signal
            wd = 2 * np.pi * self.fundamental()

            plt.scatter(envelop_time[first_index], envelop[first_index], color=&#39;r&#39;)
            plt.scatter(envelop_time[second_index], envelop[second_index], color=&#39;r&#39;)
            plt.plot(envelop_time[first_index:second_index], np.exp(zeta_omega*envelop_time[first_index:second_index]),
                     c=&#39;b&#39;)
            self.normalize().plot(&#39;envelop&#39;, **plot_kwargs)
            title = &#39;Zeta : &#39; + str(np.around(-zeta_omega/wd, 5)) + &#39; Fundamental &#39; + \
                    str(np.around(self.fundamental(), 0)) + &#39;Hz&#39;
            plt.title(title)

    def fft(self):
        &#34;&#34;&#34;
        Computes the Fast Fourier Transform of the signal and returns the vector.
        :return: Fast Fourier Transform amplitude values in a numpy array
        &#34;&#34;&#34;
        fft = np.fft.fft(self.signal)
        fft = np.abs(fft[:int(len(fft) // 2)])  # Only the symmetric of the absolute value
        return fft / np.max(fft)

    def peaks(self, max_freq=None, height=False, result=False):
        &#34;&#34;&#34;
        Computes the harmonic peaks indexes from the FFT of the signal
        :param max_freq: Supply a max frequency value overiding the one in guitarsounds_parameters
        :param height: if True the height threshold is returned to be used in the &#39;peaks&#39; plot
        :param result: if True the Scipy peak finding results dictionary is returned
        :return: peak indexes
        &#34;&#34;&#34;
        # Replace None by the default value
        if max_freq is None:
            max_freq = self.SP.general.fft_range.value

        # Get the fft and fft frequencies from the signal
        fft, fft_freq = self.fft(), self.fft_frequencies()

        # Find the max index
        max_index = np.where(fft_freq &gt;= max_freq)[0][0]

        # Find an approximation of the distance between peaks, this only works for harmonic signals
        peak_distance = np.argmax(fft) // 2

        # Maximum of the signal in a small region on both ends
        fft_max_start = np.max(fft[:peak_distance])
        fft_max_end = np.max(fft[max_index - peak_distance:max_index])

        # Build the curve below the peaks but above the noise
        exponents = np.linspace(np.log10(fft_max_start), np.log10(fft_max_end), max_index)
        intersect = 10 ** exponents[peak_distance]
        diff_start = fft_max_start - intersect  # offset by a small distance so that the first max is not a peak
        min_height = 10 ** np.linspace(np.log10(fft_max_start + diff_start), np.log10(fft_max_end), max_index)

        first_peak_indexes, _ = sig.find_peaks(fft[:max_index], height=min_height, distance=peak_distance)

        number_of_peaks = len(first_peak_indexes)
        if number_of_peaks &gt; 0:
            average_len = int(max_index / number_of_peaks) * 3
        else:
            average_len = int(max_index / 3)

        if average_len % 2 == 0:
            average_len += 1

        average_fft = sig.savgol_filter(fft[:max_index], average_len, 1, mode=&#39;mirror&#39;) * 1.9
        min_freq_index = np.where(fft_freq &gt;= 70)[0][0]
        average_fft[:min_freq_index] = 1

        peak_indexes, res = sig.find_peaks(fft[:max_index], height=average_fft, distance=min_freq_index)

        # Remove noisy peaks at the low frequencies
        while fft[peak_indexes[0]] &lt; 5e-2:
            peak_indexes = np.delete(peak_indexes, 0)
        while fft[peak_indexes[-1]] &lt; 1e-4:
            peak_indexes = np.delete(peak_indexes, -1)

        if not height and not result:
            return peak_indexes
        elif height:
            return peak_indexes, average_fft
        elif result:
            return peak_indexes, res
        elif height and result:
            return peak_indexes, height, res

    def time_damping(self):
        &#34;&#34;&#34;
        Computes the time wise damping ratio of the signal by fitting a negative exponential curve
        to the Signal envelop and computing the ratio with the Signal fundamental frequency.
        :return: The damping ratio, a scalar.
        &#34;&#34;&#34;
        # Get the envelop data
        envelop_time = self.normalize().envelop_time()
        envelop = self.normalize().envelop()

        # First point is the maximum because e^-kt is stricly decreasing
        first_index = np.argmax(envelop)

        # The second point is the first point where the signal crosses the lower_threshold line
        second_point_thresh = self.SP.damping.lower_threshold.value
        try:
            second_index = np.flatnonzero(envelop[first_index:] &lt;= second_point_thresh)[0]
        except IndexError:
            second_index = np.flatnonzero(envelop[first_index:] &lt;= second_point_thresh*2)[0]

        # Function to compute the residual for the exponential curve fit
        def residual_function(zeta_w, t, s):
            &#34;&#34;&#34;
            Function computing the residual to curve fit a negative exponential to the signal envelop
            :param zeta_w: zeta*omega constant
            :param t: time vector
            :param s: signal
            :return: residual
            &#34;&#34;&#34;
            return np.exp(zeta_w[0] * t) - s

        zeta_guess = [-0.5]

        result = scipy.optimize.least_squares(residual_function, zeta_guess,
                                              args=(envelop_time[first_index:second_index],
                                                    envelop[first_index:second_index]))
        # Get the zeta*omega constant
        zeta_omega = result.x[0]

        # Compute the fundamental frequency in radiants of the signal
        wd = 2 * np.pi * self.fundamental()
        return -zeta_omega / wd

    def peak_damping(self):
        &#34;&#34;&#34;
        Computes the frequency wise damping with the half bandwidth method on the Fourier Transform peaks
        :return: an array containing the peak damping values
        &#34;&#34;&#34;
        zetas = []
        fft_freqs = self.fft_frequencies()
        fft = self.fft()[:len(fft_freqs)]
        for peak in self.peaks():
            peak_frequency = fft_freqs[peak]
            peak_height = fft[peak]
            root_height = peak_height / np.sqrt(2)
            frequency_roots = scipy.interpolate.InterpolatedUnivariateSpline(fft_freqs, fft - root_height).roots()
            sorted_roots_indexes = np.argsort(np.abs(frequency_roots - peak_frequency))
            w2, w1 = frequency_roots[sorted_roots_indexes[:2]]
            w1, w2 = np.sort([w1, w2])
            zeta = (w2 - w1) / (2 * peak_frequency)
            zetas.append(zeta)
        return np.array(zetas)

    def fundamental(self):
        &#34;&#34;&#34;
        Returns the fundamental approximated by the first peak of the fft
        :return: fundamental value (Hz)
        &#34;&#34;&#34;
        index = self.peaks()[0]
        fundamental = self.fft_frequencies()[index]
        return fundamental

    def cavity_peak(self):
        &#34;&#34;&#34;
        Finds the Hemlotz cavity frequency index from the Fourier Transform by searching for a peak in the expected
        range (80 - 100 Hz), if the fundamental is too close to the expected Hemlotz frequency a comment
        is printed and None is returned.
        :return: If successful the cavity peak index
        &#34;&#34;&#34;
        first_index = np.where(self.fft_frequencies() &gt;= 80)[0][0]
        second_index = np.where(self.fft_frequencies() &gt;= 110)[0][0]
        cavity_peak = np.argmax(self.fft()[first_index:second_index]) + first_index
        if self.fundamental() == self.fft_frequencies()[cavity_peak]:
            print(&#39;Cavity peak is obscured by the fundamental&#39;)
        else:
            return cavity_peak

    def cavity_frequency(self):
        &#34;&#34;&#34;
        Finds the hemlotz cavity frequency from the Fourier Transform by searching for a peak in the expected
        range (80 - 100 Hz), if the fundamental is too close to the expected hemlotz frequency a comment
        is printed and None is returned.
        :return: If successful, the cavity peak frequency
        &#34;&#34;&#34;
        first_index = np.where(self.fft_frequencies() &gt;= 80)[0][0]
        second_index = np.where(self.fft_frequencies() &gt;= 110)[0][0]
        cavity_peak = np.argmax(self.fft()[first_index:second_index]) + first_index
        if self.fundamental() == self.fft_frequencies()[cavity_peak]:
            print(&#39;Cavity peak is obscured by the fundamental&#39;)
            return 0
        else:
            return self.fft_frequencies()[cavity_peak]

    def fft_frequencies(self):
        &#34;&#34;&#34;
        Computes the frequency vector associated to the Signal Fourier Transform
        :return: an array containing the frequency values.
        &#34;&#34;&#34;
        fft = self.fft()
        fft_frequencies = np.fft.fftfreq(len(fft) * 2, 1 / self.sr)  # Frequencies corresponding to the bins
        return fft_frequencies[:len(fft)]

    def fft_bins(self):
        &#34;&#34;&#34;
        Transforms the Fourier Transform signal into a statistic distribution.
        Occurences of each frequency varies from 0 to 100 according to their
        amplitude.
        :return : a list containing the frequency occurences.
        &#34;&#34;&#34;

        # Make the FT values integers
        fft_integers = [int(np.around(sample * 100, 0)) for sample in self.fft()]

        # Create a list of the frequency occurrences in the signal
        occurrences = []
        for freq, count in zip(self.fft_frequencies(), fft_integers):
            occurrences.append([freq] * count)

        # flatten the list
        return [item for sublist in occurrences for item in sublist]

    def envelop(self):
        &#34;&#34;&#34;
        Method calculating the amplitude envelope of a signal as a
        maximum of the absolute value of the signal.
        :return: Amplitude envelop of the signal
        &#34;&#34;&#34;
        # Get the hop length
        hop_length = self.SP.envelop.hop_length.value

        # Compute the envelop
        envelop = np.array(
            [np.max(np.abs(self.signal[i:i + self.SP.envelop.frame_size.value])) for i in
             range(0, len(self.signal), hop_length)])

        envelop = np.insert(envelop, 0, 0)
        return envelop

    def envelop_time(self):
        &#34;&#34;&#34;
        Method calculating the time vector associated to a signal envelop
        :return: Time vector associated to the signal envelop
        &#34;&#34;&#34;
        # Get the number of frames from the signal envelop
        frames = range(len(self.envelop()))
        # Return the envelop frames computed with Librosa
        return librosa.frames_to_time(frames, hop_length=self.SP.envelop.hop_length.value)

    def log_envelop(self):
        &#34;&#34;&#34;
        Computes the logarithmic scale envelop of the signal.
        The width of the samples increases exponentially so that
        the envelop appears having a constant window width on
        an X axis logarithmic scale.
        :return: The log envelop and the time vector associated in a tuple
        &#34;&#34;&#34;
        if self.onset is None:
            onset = np.argmax(self.signal)
        else:
            onset = self.onset

        start_time = self.SP.log_envelop.start_time.value
        while start_time &gt; (onset / self.sr):
            start_time /= 10.

        start_exponent = int(np.log10(start_time))  # closest 10^x value for smooth graph

        if self.SP.log_envelop.min_window.value is None:
            min_window = 15 ** (start_exponent + 4)
            if min_window &lt; 15:  # Value should at least be 10
                min_window = 15
        else:
            min_window = self.SP.log_envelop.min_window.value

        # initial values
        current_exponent = start_exponent
        current_time = 10 ** current_exponent  # start time on log scale
        index = int(current_time * self.sr)  # Start at the specified time
        window = min_window  # number of samples per window
        overlap = window // 2
        log_envelop = []
        log_envelop_time = [0]  # First value for comparison

        while index + window &lt;= len(self.signal):

            while log_envelop_time[-1] &lt; 10 ** (current_exponent + 1):
                if (index + window) &lt; len(self.signal):
                    log_envelop.append(np.max(self.signal[index:index + window]))
                    log_envelop_time.append(self.time()[index])
                    index += overlap
                else:
                    break

            if window * 10 &lt; self.SP.log_envelop.max_window.value:
                window = window * 10
            else:
                window = self.SP.log_envelop.max_window.value

            overlap = window // 2
            current_exponent += 1

        # remove the value where t=0 so the log scale does not break
        log_envelop_time.remove(0)

        return np.array(log_envelop), np.array(log_envelop_time)

    def find_onset(self, verbose=True):
        &#34;&#34;&#34;
        Finds the onset as an increase in more of 50% with the maximum normalized value above 0.5
        :param verbose: Prints a warning if the algorithm does not converge
        :return: the index of the onset in the signal
        &#34;&#34;&#34;
        # Index corresponding to the onset time interval
        window_index = np.ceil(self.SP.onset.onset_time.value * self.sr).astype(int)
        # Use the normalized signal to compare against a fixed value
        onset_signal = self.normalize()
        overlap = window_index // 2  # overlap for algorithm progression
        # Initial values
        increase = 0
        i = 0
        broke = False
        while increase &lt;= 0.5:
            signal_min = np.min(np.abs(onset_signal.signal[i:i + window_index]))
            signal_max = np.max(np.abs(onset_signal.signal[i:i + window_index]))
            if (signal_max &gt; 0.5) and (signal_min != 0):
                increase = signal_max / signal_min
            else:
                increase = 0
            i += overlap
            if i + window_index &gt; len(self.signal):
                if verbose:
                    print(&#39;Onset detection did not converge \n&#39;)
                    print(&#39;Approximating onset with signal max value \n&#39;)
                    broke = True
                    break
        if broke:
            return np.argmax(self.signal)
        else:
            return np.argmax(np.abs(self.signal[i:i + window_index])) + i

    def trim_onset(self, verbose=True):
        &#34;&#34;&#34;
        Trim the signal at the onset (max) minus the delay in milliseconds as
        Specified in the SoundParameters
        :param : verbose if False the warning comments are not displayed
        :return : a trimmed signal with a noise attribute
        &#34;&#34;&#34;
        # nb of samples to keep before the onset
        delay_samples = int((self.SP.onset.onset_delay.value / 1000) * self.sr)
        onset = self.find_onset(verbose=verbose)  # find the onset

        if onset &gt; delay_samples:  # To make sure the index is positive
            trimmed_signal = Signal(self.signal[onset - delay_samples:], self.sr, self.SP)
            trimmed_signal.noise = self.signal[:onset - delay_samples]
            trimmed_signal.trimmed = True
            trimmed_signal.onset = np.argmax(trimmed_signal.signal)
            return trimmed_signal

        else:
            if verbose:
                print(&#39;Signal is too short to be trimmed before onset.&#39;)
                print(&#39;&#39;)
            self.trimmed = False
            return self

    def trim_time(self, time_length):
        &#34;&#34;&#34;
        Trims the signal to the specified length and returns a new Signal instance.
        :param time_length: desired length of the new signal in seconds.
        :return: A trimmed Signal
        &#34;&#34;&#34;
        max_index = int(time_length * self.sr)
        time_trimmed_signal = Signal(self.signal[:max_index], self.sr, self.SP)
        time_trimmed_signal.time_length = time_length
        return time_trimmed_signal

    def filter_noise(self, verbose=True):
        &#34;&#34;&#34;
        Method filtering the noise from the recorded signal and returning a filtered signal.
        If the signal was not trimmed it is trimmed in place then filtered.
        If the signal can not be trimmed it can&#39;t be filtered and the original signal is returned
        :return : A Signal instance, filtered if possible.
        &#34;&#34;&#34;
        try:
            return Signal(reduce_noise(audio_clip=self.signal, noise_clip=self.noise), self.sr, self.SP)
        except AttributeError:
            if self.trimmed is False:
                if verbose:
                    print(&#39;Not sufficient noise in the raw signal, unable to filter.&#39;)
                    print(&#39;&#39;)
                return self

    def normalize(self):
        &#34;&#34;&#34;
        Normalizes the signal to [-1, 1] and returns the normalised instance.
        :return : A normalized signal
        &#34;&#34;&#34;
        factor = np.max(np.abs(self.signal))
        normalised_signal = Signal((self.signal / factor), self.sr, self.SP)
        normalised_signal.norm_factor = (1 / factor)
        return normalised_signal

    def make_freq_bins(self):
        &#34;&#34;&#34;
        Method to divide a signal in frequency bins using butterworth filters
        bins are passed as a dict, default values are :
        - bass &lt; 100 Hz
        - mid = 100 - 700 Hz
        - highmid = 700 - 2000 Hz
        - uppermid = 2000 - 4000 Hz
        - presence = 4000 - 6000 Hz
        - brillance &gt; 6000 Hz
        :return : A dictionary with the divided signal as values and bin names as keys
        &#34;&#34;&#34;

        bins = self.SP.bins.__dict__

        bass_filter = sig.butter(12, bins[&#34;bass&#34;].value, &#39;lp&#39;, fs=self.sr, output=&#39;sos&#39;)
        mid_filter = sig.butter(12, [bins[&#34;bass&#34;].value, bins[&#39;mid&#39;].value], &#39;bp&#39;, fs=self.sr, output=&#39;sos&#39;)
        himid_filter = sig.butter(12, [bins[&#34;mid&#34;].value, bins[&#39;highmid&#39;].value], &#39;bp&#39;, fs=self.sr, output=&#39;sos&#39;)
        upmid_filter = sig.butter(12, [bins[&#34;highmid&#34;].value, bins[&#39;uppermid&#39;].value], &#39;bp&#39;, fs=self.sr, output=&#39;sos&#39;)
        pres_filter = sig.butter(12, [bins[&#34;uppermid&#34;].value, bins[&#39;presence&#39;].value], &#39;bp&#39;, fs=self.sr, output=&#39;sos&#39;)
        bril_filter = sig.butter(12, bins[&#39;presence&#39;].value, &#39;hp&#39;, fs=self.sr, output=&#39;sos&#39;)

        return {
            &#34;bass&#34;: Signal(sig.sosfilt(bass_filter, self.signal), self.sr, self.SP,
                           freq_range=[0, bins[&#34;bass&#34;].value]),
            &#34;mid&#34;: Signal(sig.sosfilt(mid_filter, self.signal), self.sr, self.SP,
                          freq_range=[bins[&#34;bass&#34;].value, bins[&#34;mid&#34;].value]),
            &#34;highmid&#34;: Signal(sig.sosfilt(himid_filter, self.signal), self.sr, self.SP,
                              freq_range=[bins[&#34;mid&#34;].value, bins[&#34;highmid&#34;].value]),
            &#34;uppermid&#34;: Signal(sig.sosfilt(upmid_filter, self.signal), self.sr, self.SP,
                               freq_range=[bins[&#34;highmid&#34;].value, bins[&#34;uppermid&#34;].value]),
            &#34;presence&#34;: Signal(sig.sosfilt(pres_filter, self.signal), self.sr, self.SP,
                               freq_range=[bins[&#39;uppermid&#39;].value, bins[&#34;presence&#34;].value]),
            &#34;brillance&#34;: Signal(sig.sosfilt(bril_filter, self.signal), self.sr, self.SP,
                                freq_range=[bins[&#34;presence&#34;].value, max(self.fft_frequencies())])}

    def save_wav(self, name, path=&#39;&#39;):
        &#34;&#34;&#34;
        Create a soundfile from a signal
        :param name: the name of the saved file
        :param path: the path were the &#39;.wav&#39; file is saved
        &#34;&#34;&#34;
        write(path + name + &#34;.wav&#34;, self.signal, self.sr)


class Sound(object):
    &#34;&#34;&#34;
    A class to store audio signals obtained from a sound and compare them
    &#34;&#34;&#34;

    def __init__(self, file, name=&#39;&#39;, fundamental=None, SoundParams=None):
        &#34;&#34;&#34;
        Creates a Sound instance from a .wav file, name as a string and fundamental frequency
        value can be user specified.
        :param file: file path to the .wav file
        :param name: Sound instance name to use in plot legend and titles
        :param fundamental: Fundamental frequency value if None the value is estimated
        from the FFT (see `Signal.fundamental`).
        :param SoundParams: SoundParameters to use in the Sound instance
        &#34;&#34;&#34;
        # create a reference of the parameters
        if SoundParams is None:
            self.SP = SP
        else:
            self.SP = SoundParams

        if type(file) == str:
            # Load the soundfile using librosa
            signal, sr = librosa.load(file)
            self.file = file

        elif type(file) == tuple:
            signal, sr = file

        # create a Signal class from the signal and sample rate
        self.raw_signal = Signal(signal, sr, self.SP)

        # Allow user specified fundamental
        self.fundamental = fundamental
        self.name = name

    def condition(self, verbose=True, return_self=False):
        &#34;&#34;&#34;
        A method conditioning the Sound instance.
        - Trimming to just before the onset
        - Filtering the noise
        :param verbose: if True problem with trimming and filtering are reported
        :param return_self: If True the method returns the conditioned Sound instance
        :return: a conditioned Sound instance if `return_self = True`
        &#34;&#34;&#34;
        self.trim_signal(verbose=verbose)
        self.filter_noise(verbose=verbose)
        self.bin_divide()
        if self.fundamental is None:
            self.fundamental = self.signal.fundamental()
        if return_self:
            return self

    def use_raw_signal(self, normalized=False):
        &#34;&#34;&#34;
        Assigns the raw signal to the `signal` attribute of the Sound instance to
        analyze it
        :param normalized: if True, the raw signal is first normalized
        :return: None
        &#34;&#34;&#34;
        if normalized:
            self.signal = self.raw_signal.normalize()
        else:
            self.signal = self.raw_signal

    def bin_divide(self):
        &#34;&#34;&#34;
        Calls the `.make_freq_bins` method of the signal to create the signals associated
        to the frequency bins. The bins are all stored in the `.bin` attribute and also as
        their names (Ex: `Sound.mid` contains the mid signal).
        :return: None
        &#34;&#34;&#34;
        &#34;&#34;&#34; a method to divide the main signal into frequency bins&#34;&#34;&#34;
        # divide in frequency bins
        self.bins = self.signal.make_freq_bins()
        # unpack the bins
        self.bass, self.mid, self.highmid, self.uppermid, self.presence, self.brillance = self.bins.values()

    def filter_noise(self, verbose=True):
        &#34;&#34;&#34;
        Filters the noise in the signal attribute
        :param verbose: if True problem are printed to the terminal
        :return: None
        &#34;&#34;&#34;
        # filter the noise in the Signal class
        self.signal = self.trimmed_signal.filter_noise(verbose=verbose)

    def trim_signal(self, verbose=True):
        &#34;&#34;&#34;
        A method to trim the signal to a specific time before the onset. The time value
        can be changed in the SoundParameters.
        :param verbose: if True problems encountered are printed to the terminal
        :return: None
        &#34;&#34;&#34;
        # Trim the signal in the signal class
        self.trimmed_signal = self.raw_signal.trim_onset(verbose=verbose)

    def validate_trim(self):
        &#34;&#34;&#34;
        Graphic validation of the `.trim_onset` method.
        Used to see if the signal onset was determined accurately
        :return: None
        &#34;&#34;&#34;
        if hasattr(self, &#39;trimmed_signal&#39;):
            fig, (ax1, ax2) = plt.subplots(2, figsize=(10, 6))
            ax1.plot(self.raw_signal.envelop_time(), self.raw_signal.envelop(), color=&#39;k&#39;)
            ax1.set(title=&#39;Old Envelop&#39;, xlabel=&#39;time&#39;, ylabel=&#39;amplitude&#39;)
            ax2.plot(self.trimmed_signal.envelop_time(), self.trimmed_signal.envelop(), color=&#39;k&#39;)
            onset_index = self.trimmed_signal.onset
            ax2.scatter(self.trimmed_signal.time()[onset_index], self.trimmed_signal.signal[onset_index], color=&#39;r&#39;)
            ax2.set(title=&#39;Trimmed signal&#39;, xlabel=&#39;time&#39;, ylabel=&#39;amplitude&#39;)
            plt.tight_layout()
        else:
            print(&#39;signal was not trimmed&#39;)

    def validate_noise(self):
        &#34;&#34;&#34;
        Audio validation of the `.filter_noise()` method.
        Allows the user to listen to the filtered and unfiltered signals
        in a jupyter notebook
        :return: None
        &#34;&#34;&#34;
        if hasattr(self, &#39;trimmed_signal&#39;):
            print(&#39;not filtered&#39;)
            self.trimmed_signal.listen()
            print(&#39;filtered&#39;)
            self.signal.listen()
        else:
            print(&#39;signal was not filtered&#39;)

    def listen_freq_bins(self):
        &#34;&#34;&#34;
        Method to listen to all the frequency bins of a sound
        in a Jupyter Notebook
        :return : None
        &#34;&#34;&#34;
        for key in self.bins.keys():
            print(key)
            self.bins[key].listen()

    def plot_freq_bins(self, bins=None):
        &#34;&#34;&#34;
        Method to plot all the frequency bins of a sound
        :param bins: frequency bins as a list to plot on the graph
        if none are specified, all the bins are plotted.
        &#34;&#34;&#34;
        if bins is None:
            bins = self.bins.keys()
        for key in bins:
            lab = key + &#39; : &#39; + str(int(self.bins[key].range[0])) + &#39; - &#39; + str(int(self.bins[key].range[1])) + &#39; Hz&#39;
            self.bins[key].plot(&#39;log envelop&#39;, label=lab)
        plt.xscale(&#39;log&#39;)
        plt.yscale(&#39;log&#39;)
        plt.legend()</code></pre>
</details>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-variables">Global variables</h2>
<dl>
<dt id="guitarsounds.SP"><code class="name">var <span class="ident">SP</span></code></dt>
<dd>
<div class="desc"><p>Classes</p></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="guitarsounds.Signal"><code class="flex name class">
<span>class <span class="ident">Signal</span></span>
<span>(</span><span>signal, sr, SoundParam, freq_range=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A Class to do computations on an audio signal.</p>
<p>The signal is never changed in the class, when transformations are made, a new instance is returned.</p>
<p>Create a Signal class from a vector of samples and a sample rate</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Signal(object):
    &#34;&#34;&#34;
    A Class to do computations on an audio signal.

    The signal is never changed in the class, when transformations are made, a new instance is returned.

    &#34;&#34;&#34;

    def __init__(self, signal, sr, SoundParam, freq_range=None):
        &#34;&#34;&#34; Create a Signal class from a vector of samples and a sample rate&#34;&#34;&#34;
        self.SP = SoundParam
        self.onset = None
        self.signal = signal
        self.sr = sr
        self.range = freq_range
        self.trimmed = None
        self.noise = None

    def time(self):
        &#34;&#34;&#34;
        Returns the time vector associated to the signal
        :return: numpy array corresponding to the time values of the signal samples in seconds
        &#34;&#34;&#34;
        return np.arange(0, len(self.signal) * (1 / self.sr), 1 / self.sr)

    def listen(self):
        &#34;&#34;&#34;Method to listen the sound signal in a Jupyter Notebook&#34;&#34;&#34;
        file = &#39;temp.wav&#39;
        write(file, self.signal, self.sr)
        ipd.display(ipd.Audio(file))
        os.remove(file)

    # noinspection PyUnresolvedReferences
    def plot(self, kind, **kwargs):
        &#34;&#34;&#34;
        General plotting method for the Signal class, supported plots are:

        &#39;signal&#39; :
            Plots the time varying real signal as amplitude vs time.

        &#39;envelop&#39; :
            Plots the envelop of the signal as amplitude vs time.

        &#39;log envelop&#39; :
            Plots the envelop with logarithmic window widths on a logarithmic x axis scale.

        &#39;fft&#39; :
            Plots the Fourier Transform of the Signal.
            If `ticks = &#39;bins&#39;` is supplied in the keyword arguments, the frequency ticks are replaced
            with the frequency bin values

        &#39;fft hist&#39; :
            Plots the octave based Fourier Transform Histogram.
            Both axes are on a log scale.
            If `ticks = &#39;bins&#39;` is supplied in the keyword arguments, the frequency ticks are replaced
            with the frequency bin values

        &#39;peaks&#39; :
            Plots the Fourier Transform of the Signal, with the peaks detected with the `Signal.peaks()` method.
            If `peak_height = True` is supplied in the keyword arguments the computed height threshold is
            shown on the plot.

        &#39;peak damping&#39; :
            Plots the frequency vs damping scatter of the damping ratio computed from the
            Fourier Transform peak shapes. A polynomial curve fit is added to help visualisation.
            Supported key word arguments are :
            `n=5` : The order of the fitted polynomial curve, default is 5,
            if the supplied value is too high, it will be reduced until the number of peaks
            is sufficient to fit the polynomial.

            `inverse=True` : Default value is True, if False, the damping ratio is shown instead
            of its inverse.

            `normalize=False` : Default value is False, if True the damping values are normalized
            from 0 to 1, to help analyze results and compare Sounds.

            `ticks=None` : Default value is None, if `ticks=&#39;bins&#39;` the x axis ticks are replaced with
            frequency bin values.

        &#39;time damping&#39; :
            Shows the signal envelop with the fitted negative exponential curve used to determine the
            time damping ratio of the signal.
        &#34;&#34;&#34;
        illegal_kwargs = [&#39;max_time&#39;, &#39;n&#39;, &#39;ticks&#39;, &#39;normalize&#39;, &#39;inverse&#39;, &#39;peak_height&#39;]
        plot_kwargs = {i: kwargs[i] for i in kwargs if i not in illegal_kwargs}

        if kind == &#39;signal&#39;:

            plt.plot(self.time(), self.signal, alpha=0.6, **plot_kwargs)
            plt.xlabel(&#39;time (s)&#39;)
            plt.ylabel(&#39;amplitude&#39;)

        elif kind == &#39;envelop&#39;:

            plt.plot(self.envelop_time(), self.envelop(), **plot_kwargs)
            plt.xlabel(&#34;time (s)&#34;)
            plt.ylabel(&#34;amplitude&#34;)
            plt.grid(&#39;on&#39;)

        elif kind == &#39;log envelop&#39;:
            log_envelop, log_envelop_time = self.log_envelop()
            if (&#39;max_time&#39; in kwargs.keys()) and (kwargs[&#39;max_time&#39;] &lt; log_envelop_time[-1]):
                    max_index = np.nonzero(log_envelop_time &gt;= kwargs[&#39;max_time&#39;])[0][0]
            else:
                max_index = len(log_envelop_time)

            plt.plot(log_envelop_time[:max_index], log_envelop[:max_index], **plot_kwargs)
            plt.xlabel(&#34;time (s)&#34;)
            plt.ylabel(&#34;amplitude&#34;)
            plt.xscale(&#39;log&#39;)
            plt.grid(&#39;on&#39;)

        elif kind == &#39;fft&#39;:
            # find the index corresponding to the fft range
            result = np.where(self.fft_frequencies() &gt;= self.SP.general.fft_range.value)[0]
            if len(result) == 0:
                last_index = -1
            else:
                last_index = result[0]
            plt.plot(self.fft_frequencies()[:last_index], self.fft()[:last_index], **plot_kwargs)
            plt.xlabel(&#34;frequency&#34;),
            plt.ylabel(&#34;amplitude&#34;),
            plt.yscale(&#39;log&#39;)
            plt.grid(&#39;on&#39;)

            if &#39;ticks&#39; in kwargs and kwargs[&#39;ticks&#39;] == &#39;bins&#39;:
                labels = [label for label in self.SP.bins.__dict__ if label != &#39;name&#39;]
                labels.append(&#39;brillance&#39;)
                x = [param.value for param in self.SP.bins.__dict__.values() if param != &#39;bins&#39;]
                x.append(11250)
                x_formatter = matplotlib.ticker.FixedFormatter(labels)
                x_locator = matplotlib.ticker.FixedLocator(x)
                ax = plt.gca()
                ax.xaxis.set_major_locator(x_locator)
                ax.xaxis.set_major_formatter(x_formatter)
                ax.tick_params(axis=&#34;x&#34;, labelrotation=90)

        elif kind == &#39;fft hist&#39;:
            # Histogram of frequency values occurences in octave bins
            plt.hist(self.fft_bins(), utils.octave_histogram(self.SP.general.octave_fraction.value),
                     alpha=0.7, **plot_kwargs)
            plt.xlabel(&#39;Fréquence (Hz)&#39;)
            plt.ylabel(&#39;Amplitude&#39;)
            plt.xscale(&#39;log&#39;)
            plt.yscale(&#39;log&#39;)
            plt.grid(&#39;on&#39;)

            if &#39;ticks&#39; in kwargs and kwargs[&#39;ticks&#39;] == &#39;bins&#39;:
                labels = [label for label in self.SP.bins.__dict__ if label != &#39;name&#39;]
                labels.append(&#39;brillance&#39;)
                x = [param.value for param in self.SP.bins.__dict__.values() if param != &#39;bins&#39;]
                x.append(11250)
                x_formatter = matplotlib.ticker.FixedFormatter(labels)
                x_locator = matplotlib.ticker.FixedLocator(x)
                ax = plt.gca()
                ax.xaxis.set_major_locator(x_locator)
                ax.xaxis.set_major_formatter(x_formatter)
                ax.tick_params(axis=&#34;x&#34;, labelrotation=90)

        elif kind == &#39;peaks&#39;:
            fft_freqs = self.fft_frequencies()
            fft = self.fft()
            max_index = np.where(fft_freqs &gt;= self.SP.general.fft_range.value)[0][0]
            peak_indexes, height = self.peaks(height=True)
            plt.xlabel(&#39;Fréquence (Hz)&#39;)
            plt.ylabel(&#39;Amplitude&#39;)
            plt.yscale(&#39;log&#39;)
            plt.grid(&#39;on&#39;)

            if &#39;color&#39; not in plot_kwargs.keys():
                plot_kwargs[&#39;color&#39;] = &#39;k&#39;
            plt.plot(fft_freqs[:max_index], fft[:max_index], **plot_kwargs)
            plt.scatter(fft_freqs[peak_indexes], fft[peak_indexes], color=&#39;r&#39;)
            if (&#39;peak_height&#39; in kwargs.keys()) and (kwargs[&#39;peak_height&#39;]):
                plt.plot(fft_freqs[:max_index], height, color=&#39;r&#39;)

        elif kind == &#39;peak damping&#39;:
            # Get the damping ration and peak frequencies
            if &#39;inverse&#39; in kwargs.keys() and kwargs[&#39;inverse&#39;] is False:
                zetas = np.array(self.peak_damping())
                ylabel = r&#39;Damping $\zeta$&#39;
            else:
                zetas = 1 / np.array(self.peak_damping())
                ylabel = r&#39;Inverse Damping $1/\zeta$&#39;

            peak_freqs = self.fft_frequencies()[self.peaks()]

            # If a polynomial order is supplied assign it, if not default is 5
            if &#39;n&#39; in kwargs.keys():
                n = kwargs[&#39;n&#39;]
            else:
                n = 5

            # If labels are supplied the default color are used
            if &#39;label&#39; in plot_kwargs:
                plot_kwargs[&#39;color&#39;] = None
                plot2_kwargs = plot_kwargs.copy()
                plot2_kwargs[&#39;label&#39;] = None

            # If not black and red are used
            else:
                plot_kwargs[&#39;color&#39;] = &#39;r&#39;
                plot2_kwargs = plot_kwargs.copy()
                plot2_kwargs[&#39;color&#39;] = &#39;k&#39;

            if &#39;normalize&#39; in kwargs.keys() and kwargs[&#39;normalize&#39;]:
                zetas = np.array(zetas)/np.array(zetas).max()

            plt.scatter(peak_freqs, zetas, **plot_kwargs)
            fun = utils.nth_order_polynomial_fit(n, peak_freqs, zetas)
            freq = np.linspace(peak_freqs[0], peak_freqs[-1], 100)
            plt.plot(freq, fun(freq), **plot2_kwargs)
            plt.grid(&#39;on&#39;)
            plt.title(&#39;Frequency vs Damping Factor with Order &#39; + str(n))
            plt.xlabel(&#39;Frequency (Hz)&#39;)
            plt.ylabel(ylabel)

            if &#39;ticks&#39; in kwargs and kwargs[&#39;ticks&#39;] == &#39;bins&#39;:
                labels = [label for label in self.SP.bins.__dict__ if label != &#39;name&#39;]
                labels.append(&#39;brillance&#39;)
                x = [param.value for param in self.SP.bins.__dict__.values() if param != &#39;bins&#39;]
                x.append(11250)
                x_formatter = matplotlib.ticker.FixedFormatter(labels)
                x_locator = matplotlib.ticker.FixedLocator(x)
                ax = plt.gca()
                ax.xaxis.set_major_locator(x_locator)
                ax.xaxis.set_major_formatter(x_formatter)
                ax.tick_params(axis=&#34;x&#34;, labelrotation=90)

        elif kind == &#39;time damping&#39;:
            # Get the envelop data
            envelop_time = self.normalize().envelop_time()
            envelop = self.normalize().envelop()

            # First point is the maximum because e^-kt is stricly decreasing
            first_index = np.argmax(envelop)

            # The second point is the first point where the signal crosses the lower_threshold line
            second_point_thresh = self.SP.damping.lower_threshold.value

            try:
                second_index = np.flatnonzero(envelop[first_index:] &lt;= second_point_thresh)[0]
            except IndexError:
                second_index = np.flatnonzero(envelop[first_index:] &lt;= second_point_thresh * 2)[0]

            # Function to compute the residual for the exponential curve fit
            def residual_function(zeta_w, t, s):
                return np.exp(zeta_w[0] * t) - s
            zeta_guess = [-0.5]

            result = scipy.optimize.least_squares(residual_function, zeta_guess,
                                                  args=(envelop_time[first_index:second_index],
                                                        envelop[first_index:second_index]))
            # Get the zeta*omega constant
            zeta_omega = result.x[0]

            # Compute the fundamental frequency in radiants of the signal
            wd = 2 * np.pi * self.fundamental()

            plt.scatter(envelop_time[first_index], envelop[first_index], color=&#39;r&#39;)
            plt.scatter(envelop_time[second_index], envelop[second_index], color=&#39;r&#39;)
            plt.plot(envelop_time[first_index:second_index], np.exp(zeta_omega*envelop_time[first_index:second_index]),
                     c=&#39;b&#39;)
            self.normalize().plot(&#39;envelop&#39;, **plot_kwargs)
            title = &#39;Zeta : &#39; + str(np.around(-zeta_omega/wd, 5)) + &#39; Fundamental &#39; + \
                    str(np.around(self.fundamental(), 0)) + &#39;Hz&#39;
            plt.title(title)

    def fft(self):
        &#34;&#34;&#34;
        Computes the Fast Fourier Transform of the signal and returns the vector.
        :return: Fast Fourier Transform amplitude values in a numpy array
        &#34;&#34;&#34;
        fft = np.fft.fft(self.signal)
        fft = np.abs(fft[:int(len(fft) // 2)])  # Only the symmetric of the absolute value
        return fft / np.max(fft)

    def peaks(self, max_freq=None, height=False, result=False):
        &#34;&#34;&#34;
        Computes the harmonic peaks indexes from the FFT of the signal
        :param max_freq: Supply a max frequency value overiding the one in guitarsounds_parameters
        :param height: if True the height threshold is returned to be used in the &#39;peaks&#39; plot
        :param result: if True the Scipy peak finding results dictionary is returned
        :return: peak indexes
        &#34;&#34;&#34;
        # Replace None by the default value
        if max_freq is None:
            max_freq = self.SP.general.fft_range.value

        # Get the fft and fft frequencies from the signal
        fft, fft_freq = self.fft(), self.fft_frequencies()

        # Find the max index
        max_index = np.where(fft_freq &gt;= max_freq)[0][0]

        # Find an approximation of the distance between peaks, this only works for harmonic signals
        peak_distance = np.argmax(fft) // 2

        # Maximum of the signal in a small region on both ends
        fft_max_start = np.max(fft[:peak_distance])
        fft_max_end = np.max(fft[max_index - peak_distance:max_index])

        # Build the curve below the peaks but above the noise
        exponents = np.linspace(np.log10(fft_max_start), np.log10(fft_max_end), max_index)
        intersect = 10 ** exponents[peak_distance]
        diff_start = fft_max_start - intersect  # offset by a small distance so that the first max is not a peak
        min_height = 10 ** np.linspace(np.log10(fft_max_start + diff_start), np.log10(fft_max_end), max_index)

        first_peak_indexes, _ = sig.find_peaks(fft[:max_index], height=min_height, distance=peak_distance)

        number_of_peaks = len(first_peak_indexes)
        if number_of_peaks &gt; 0:
            average_len = int(max_index / number_of_peaks) * 3
        else:
            average_len = int(max_index / 3)

        if average_len % 2 == 0:
            average_len += 1

        average_fft = sig.savgol_filter(fft[:max_index], average_len, 1, mode=&#39;mirror&#39;) * 1.9
        min_freq_index = np.where(fft_freq &gt;= 70)[0][0]
        average_fft[:min_freq_index] = 1

        peak_indexes, res = sig.find_peaks(fft[:max_index], height=average_fft, distance=min_freq_index)

        # Remove noisy peaks at the low frequencies
        while fft[peak_indexes[0]] &lt; 5e-2:
            peak_indexes = np.delete(peak_indexes, 0)
        while fft[peak_indexes[-1]] &lt; 1e-4:
            peak_indexes = np.delete(peak_indexes, -1)

        if not height and not result:
            return peak_indexes
        elif height:
            return peak_indexes, average_fft
        elif result:
            return peak_indexes, res
        elif height and result:
            return peak_indexes, height, res

    def time_damping(self):
        &#34;&#34;&#34;
        Computes the time wise damping ratio of the signal by fitting a negative exponential curve
        to the Signal envelop and computing the ratio with the Signal fundamental frequency.
        :return: The damping ratio, a scalar.
        &#34;&#34;&#34;
        # Get the envelop data
        envelop_time = self.normalize().envelop_time()
        envelop = self.normalize().envelop()

        # First point is the maximum because e^-kt is stricly decreasing
        first_index = np.argmax(envelop)

        # The second point is the first point where the signal crosses the lower_threshold line
        second_point_thresh = self.SP.damping.lower_threshold.value
        try:
            second_index = np.flatnonzero(envelop[first_index:] &lt;= second_point_thresh)[0]
        except IndexError:
            second_index = np.flatnonzero(envelop[first_index:] &lt;= second_point_thresh*2)[0]

        # Function to compute the residual for the exponential curve fit
        def residual_function(zeta_w, t, s):
            &#34;&#34;&#34;
            Function computing the residual to curve fit a negative exponential to the signal envelop
            :param zeta_w: zeta*omega constant
            :param t: time vector
            :param s: signal
            :return: residual
            &#34;&#34;&#34;
            return np.exp(zeta_w[0] * t) - s

        zeta_guess = [-0.5]

        result = scipy.optimize.least_squares(residual_function, zeta_guess,
                                              args=(envelop_time[first_index:second_index],
                                                    envelop[first_index:second_index]))
        # Get the zeta*omega constant
        zeta_omega = result.x[0]

        # Compute the fundamental frequency in radiants of the signal
        wd = 2 * np.pi * self.fundamental()
        return -zeta_omega / wd

    def peak_damping(self):
        &#34;&#34;&#34;
        Computes the frequency wise damping with the half bandwidth method on the Fourier Transform peaks
        :return: an array containing the peak damping values
        &#34;&#34;&#34;
        zetas = []
        fft_freqs = self.fft_frequencies()
        fft = self.fft()[:len(fft_freqs)]
        for peak in self.peaks():
            peak_frequency = fft_freqs[peak]
            peak_height = fft[peak]
            root_height = peak_height / np.sqrt(2)
            frequency_roots = scipy.interpolate.InterpolatedUnivariateSpline(fft_freqs, fft - root_height).roots()
            sorted_roots_indexes = np.argsort(np.abs(frequency_roots - peak_frequency))
            w2, w1 = frequency_roots[sorted_roots_indexes[:2]]
            w1, w2 = np.sort([w1, w2])
            zeta = (w2 - w1) / (2 * peak_frequency)
            zetas.append(zeta)
        return np.array(zetas)

    def fundamental(self):
        &#34;&#34;&#34;
        Returns the fundamental approximated by the first peak of the fft
        :return: fundamental value (Hz)
        &#34;&#34;&#34;
        index = self.peaks()[0]
        fundamental = self.fft_frequencies()[index]
        return fundamental

    def cavity_peak(self):
        &#34;&#34;&#34;
        Finds the Hemlotz cavity frequency index from the Fourier Transform by searching for a peak in the expected
        range (80 - 100 Hz), if the fundamental is too close to the expected Hemlotz frequency a comment
        is printed and None is returned.
        :return: If successful the cavity peak index
        &#34;&#34;&#34;
        first_index = np.where(self.fft_frequencies() &gt;= 80)[0][0]
        second_index = np.where(self.fft_frequencies() &gt;= 110)[0][0]
        cavity_peak = np.argmax(self.fft()[first_index:second_index]) + first_index
        if self.fundamental() == self.fft_frequencies()[cavity_peak]:
            print(&#39;Cavity peak is obscured by the fundamental&#39;)
        else:
            return cavity_peak

    def cavity_frequency(self):
        &#34;&#34;&#34;
        Finds the hemlotz cavity frequency from the Fourier Transform by searching for a peak in the expected
        range (80 - 100 Hz), if the fundamental is too close to the expected hemlotz frequency a comment
        is printed and None is returned.
        :return: If successful, the cavity peak frequency
        &#34;&#34;&#34;
        first_index = np.where(self.fft_frequencies() &gt;= 80)[0][0]
        second_index = np.where(self.fft_frequencies() &gt;= 110)[0][0]
        cavity_peak = np.argmax(self.fft()[first_index:second_index]) + first_index
        if self.fundamental() == self.fft_frequencies()[cavity_peak]:
            print(&#39;Cavity peak is obscured by the fundamental&#39;)
            return 0
        else:
            return self.fft_frequencies()[cavity_peak]

    def fft_frequencies(self):
        &#34;&#34;&#34;
        Computes the frequency vector associated to the Signal Fourier Transform
        :return: an array containing the frequency values.
        &#34;&#34;&#34;
        fft = self.fft()
        fft_frequencies = np.fft.fftfreq(len(fft) * 2, 1 / self.sr)  # Frequencies corresponding to the bins
        return fft_frequencies[:len(fft)]

    def fft_bins(self):
        &#34;&#34;&#34;
        Transforms the Fourier Transform signal into a statistic distribution.
        Occurences of each frequency varies from 0 to 100 according to their
        amplitude.
        :return : a list containing the frequency occurences.
        &#34;&#34;&#34;

        # Make the FT values integers
        fft_integers = [int(np.around(sample * 100, 0)) for sample in self.fft()]

        # Create a list of the frequency occurrences in the signal
        occurrences = []
        for freq, count in zip(self.fft_frequencies(), fft_integers):
            occurrences.append([freq] * count)

        # flatten the list
        return [item for sublist in occurrences for item in sublist]

    def envelop(self):
        &#34;&#34;&#34;
        Method calculating the amplitude envelope of a signal as a
        maximum of the absolute value of the signal.
        :return: Amplitude envelop of the signal
        &#34;&#34;&#34;
        # Get the hop length
        hop_length = self.SP.envelop.hop_length.value

        # Compute the envelop
        envelop = np.array(
            [np.max(np.abs(self.signal[i:i + self.SP.envelop.frame_size.value])) for i in
             range(0, len(self.signal), hop_length)])

        envelop = np.insert(envelop, 0, 0)
        return envelop

    def envelop_time(self):
        &#34;&#34;&#34;
        Method calculating the time vector associated to a signal envelop
        :return: Time vector associated to the signal envelop
        &#34;&#34;&#34;
        # Get the number of frames from the signal envelop
        frames = range(len(self.envelop()))
        # Return the envelop frames computed with Librosa
        return librosa.frames_to_time(frames, hop_length=self.SP.envelop.hop_length.value)

    def log_envelop(self):
        &#34;&#34;&#34;
        Computes the logarithmic scale envelop of the signal.
        The width of the samples increases exponentially so that
        the envelop appears having a constant window width on
        an X axis logarithmic scale.
        :return: The log envelop and the time vector associated in a tuple
        &#34;&#34;&#34;
        if self.onset is None:
            onset = np.argmax(self.signal)
        else:
            onset = self.onset

        start_time = self.SP.log_envelop.start_time.value
        while start_time &gt; (onset / self.sr):
            start_time /= 10.

        start_exponent = int(np.log10(start_time))  # closest 10^x value for smooth graph

        if self.SP.log_envelop.min_window.value is None:
            min_window = 15 ** (start_exponent + 4)
            if min_window &lt; 15:  # Value should at least be 10
                min_window = 15
        else:
            min_window = self.SP.log_envelop.min_window.value

        # initial values
        current_exponent = start_exponent
        current_time = 10 ** current_exponent  # start time on log scale
        index = int(current_time * self.sr)  # Start at the specified time
        window = min_window  # number of samples per window
        overlap = window // 2
        log_envelop = []
        log_envelop_time = [0]  # First value for comparison

        while index + window &lt;= len(self.signal):

            while log_envelop_time[-1] &lt; 10 ** (current_exponent + 1):
                if (index + window) &lt; len(self.signal):
                    log_envelop.append(np.max(self.signal[index:index + window]))
                    log_envelop_time.append(self.time()[index])
                    index += overlap
                else:
                    break

            if window * 10 &lt; self.SP.log_envelop.max_window.value:
                window = window * 10
            else:
                window = self.SP.log_envelop.max_window.value

            overlap = window // 2
            current_exponent += 1

        # remove the value where t=0 so the log scale does not break
        log_envelop_time.remove(0)

        return np.array(log_envelop), np.array(log_envelop_time)

    def find_onset(self, verbose=True):
        &#34;&#34;&#34;
        Finds the onset as an increase in more of 50% with the maximum normalized value above 0.5
        :param verbose: Prints a warning if the algorithm does not converge
        :return: the index of the onset in the signal
        &#34;&#34;&#34;
        # Index corresponding to the onset time interval
        window_index = np.ceil(self.SP.onset.onset_time.value * self.sr).astype(int)
        # Use the normalized signal to compare against a fixed value
        onset_signal = self.normalize()
        overlap = window_index // 2  # overlap for algorithm progression
        # Initial values
        increase = 0
        i = 0
        broke = False
        while increase &lt;= 0.5:
            signal_min = np.min(np.abs(onset_signal.signal[i:i + window_index]))
            signal_max = np.max(np.abs(onset_signal.signal[i:i + window_index]))
            if (signal_max &gt; 0.5) and (signal_min != 0):
                increase = signal_max / signal_min
            else:
                increase = 0
            i += overlap
            if i + window_index &gt; len(self.signal):
                if verbose:
                    print(&#39;Onset detection did not converge \n&#39;)
                    print(&#39;Approximating onset with signal max value \n&#39;)
                    broke = True
                    break
        if broke:
            return np.argmax(self.signal)
        else:
            return np.argmax(np.abs(self.signal[i:i + window_index])) + i

    def trim_onset(self, verbose=True):
        &#34;&#34;&#34;
        Trim the signal at the onset (max) minus the delay in milliseconds as
        Specified in the SoundParameters
        :param : verbose if False the warning comments are not displayed
        :return : a trimmed signal with a noise attribute
        &#34;&#34;&#34;
        # nb of samples to keep before the onset
        delay_samples = int((self.SP.onset.onset_delay.value / 1000) * self.sr)
        onset = self.find_onset(verbose=verbose)  # find the onset

        if onset &gt; delay_samples:  # To make sure the index is positive
            trimmed_signal = Signal(self.signal[onset - delay_samples:], self.sr, self.SP)
            trimmed_signal.noise = self.signal[:onset - delay_samples]
            trimmed_signal.trimmed = True
            trimmed_signal.onset = np.argmax(trimmed_signal.signal)
            return trimmed_signal

        else:
            if verbose:
                print(&#39;Signal is too short to be trimmed before onset.&#39;)
                print(&#39;&#39;)
            self.trimmed = False
            return self

    def trim_time(self, time_length):
        &#34;&#34;&#34;
        Trims the signal to the specified length and returns a new Signal instance.
        :param time_length: desired length of the new signal in seconds.
        :return: A trimmed Signal
        &#34;&#34;&#34;
        max_index = int(time_length * self.sr)
        time_trimmed_signal = Signal(self.signal[:max_index], self.sr, self.SP)
        time_trimmed_signal.time_length = time_length
        return time_trimmed_signal

    def filter_noise(self, verbose=True):
        &#34;&#34;&#34;
        Method filtering the noise from the recorded signal and returning a filtered signal.
        If the signal was not trimmed it is trimmed in place then filtered.
        If the signal can not be trimmed it can&#39;t be filtered and the original signal is returned
        :return : A Signal instance, filtered if possible.
        &#34;&#34;&#34;
        try:
            return Signal(reduce_noise(audio_clip=self.signal, noise_clip=self.noise), self.sr, self.SP)
        except AttributeError:
            if self.trimmed is False:
                if verbose:
                    print(&#39;Not sufficient noise in the raw signal, unable to filter.&#39;)
                    print(&#39;&#39;)
                return self

    def normalize(self):
        &#34;&#34;&#34;
        Normalizes the signal to [-1, 1] and returns the normalised instance.
        :return : A normalized signal
        &#34;&#34;&#34;
        factor = np.max(np.abs(self.signal))
        normalised_signal = Signal((self.signal / factor), self.sr, self.SP)
        normalised_signal.norm_factor = (1 / factor)
        return normalised_signal

    def make_freq_bins(self):
        &#34;&#34;&#34;
        Method to divide a signal in frequency bins using butterworth filters
        bins are passed as a dict, default values are :
        - bass &lt; 100 Hz
        - mid = 100 - 700 Hz
        - highmid = 700 - 2000 Hz
        - uppermid = 2000 - 4000 Hz
        - presence = 4000 - 6000 Hz
        - brillance &gt; 6000 Hz
        :return : A dictionary with the divided signal as values and bin names as keys
        &#34;&#34;&#34;

        bins = self.SP.bins.__dict__

        bass_filter = sig.butter(12, bins[&#34;bass&#34;].value, &#39;lp&#39;, fs=self.sr, output=&#39;sos&#39;)
        mid_filter = sig.butter(12, [bins[&#34;bass&#34;].value, bins[&#39;mid&#39;].value], &#39;bp&#39;, fs=self.sr, output=&#39;sos&#39;)
        himid_filter = sig.butter(12, [bins[&#34;mid&#34;].value, bins[&#39;highmid&#39;].value], &#39;bp&#39;, fs=self.sr, output=&#39;sos&#39;)
        upmid_filter = sig.butter(12, [bins[&#34;highmid&#34;].value, bins[&#39;uppermid&#39;].value], &#39;bp&#39;, fs=self.sr, output=&#39;sos&#39;)
        pres_filter = sig.butter(12, [bins[&#34;uppermid&#34;].value, bins[&#39;presence&#39;].value], &#39;bp&#39;, fs=self.sr, output=&#39;sos&#39;)
        bril_filter = sig.butter(12, bins[&#39;presence&#39;].value, &#39;hp&#39;, fs=self.sr, output=&#39;sos&#39;)

        return {
            &#34;bass&#34;: Signal(sig.sosfilt(bass_filter, self.signal), self.sr, self.SP,
                           freq_range=[0, bins[&#34;bass&#34;].value]),
            &#34;mid&#34;: Signal(sig.sosfilt(mid_filter, self.signal), self.sr, self.SP,
                          freq_range=[bins[&#34;bass&#34;].value, bins[&#34;mid&#34;].value]),
            &#34;highmid&#34;: Signal(sig.sosfilt(himid_filter, self.signal), self.sr, self.SP,
                              freq_range=[bins[&#34;mid&#34;].value, bins[&#34;highmid&#34;].value]),
            &#34;uppermid&#34;: Signal(sig.sosfilt(upmid_filter, self.signal), self.sr, self.SP,
                               freq_range=[bins[&#34;highmid&#34;].value, bins[&#34;uppermid&#34;].value]),
            &#34;presence&#34;: Signal(sig.sosfilt(pres_filter, self.signal), self.sr, self.SP,
                               freq_range=[bins[&#39;uppermid&#39;].value, bins[&#34;presence&#34;].value]),
            &#34;brillance&#34;: Signal(sig.sosfilt(bril_filter, self.signal), self.sr, self.SP,
                                freq_range=[bins[&#34;presence&#34;].value, max(self.fft_frequencies())])}

    def save_wav(self, name, path=&#39;&#39;):
        &#34;&#34;&#34;
        Create a soundfile from a signal
        :param name: the name of the saved file
        :param path: the path were the &#39;.wav&#39; file is saved
        &#34;&#34;&#34;
        write(path + name + &#34;.wav&#34;, self.signal, self.sr)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="guitarsounds.Signal.cavity_frequency"><code class="name flex">
<span>def <span class="ident">cavity_frequency</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds the hemlotz cavity frequency from the Fourier Transform by searching for a peak in the expected
range (80 - 100 Hz), if the fundamental is too close to the expected hemlotz frequency a comment
is printed and None is returned.
:return: If successful, the cavity peak frequency</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cavity_frequency(self):
    &#34;&#34;&#34;
    Finds the hemlotz cavity frequency from the Fourier Transform by searching for a peak in the expected
    range (80 - 100 Hz), if the fundamental is too close to the expected hemlotz frequency a comment
    is printed and None is returned.
    :return: If successful, the cavity peak frequency
    &#34;&#34;&#34;
    first_index = np.where(self.fft_frequencies() &gt;= 80)[0][0]
    second_index = np.where(self.fft_frequencies() &gt;= 110)[0][0]
    cavity_peak = np.argmax(self.fft()[first_index:second_index]) + first_index
    if self.fundamental() == self.fft_frequencies()[cavity_peak]:
        print(&#39;Cavity peak is obscured by the fundamental&#39;)
        return 0
    else:
        return self.fft_frequencies()[cavity_peak]</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.cavity_peak"><code class="name flex">
<span>def <span class="ident">cavity_peak</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds the Hemlotz cavity frequency index from the Fourier Transform by searching for a peak in the expected
range (80 - 100 Hz), if the fundamental is too close to the expected Hemlotz frequency a comment
is printed and None is returned.
:return: If successful the cavity peak index</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cavity_peak(self):
    &#34;&#34;&#34;
    Finds the Hemlotz cavity frequency index from the Fourier Transform by searching for a peak in the expected
    range (80 - 100 Hz), if the fundamental is too close to the expected Hemlotz frequency a comment
    is printed and None is returned.
    :return: If successful the cavity peak index
    &#34;&#34;&#34;
    first_index = np.where(self.fft_frequencies() &gt;= 80)[0][0]
    second_index = np.where(self.fft_frequencies() &gt;= 110)[0][0]
    cavity_peak = np.argmax(self.fft()[first_index:second_index]) + first_index
    if self.fundamental() == self.fft_frequencies()[cavity_peak]:
        print(&#39;Cavity peak is obscured by the fundamental&#39;)
    else:
        return cavity_peak</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.envelop"><code class="name flex">
<span>def <span class="ident">envelop</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method calculating the amplitude envelope of a signal as a
maximum of the absolute value of the signal.
:return: Amplitude envelop of the signal</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def envelop(self):
    &#34;&#34;&#34;
    Method calculating the amplitude envelope of a signal as a
    maximum of the absolute value of the signal.
    :return: Amplitude envelop of the signal
    &#34;&#34;&#34;
    # Get the hop length
    hop_length = self.SP.envelop.hop_length.value

    # Compute the envelop
    envelop = np.array(
        [np.max(np.abs(self.signal[i:i + self.SP.envelop.frame_size.value])) for i in
         range(0, len(self.signal), hop_length)])

    envelop = np.insert(envelop, 0, 0)
    return envelop</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.envelop_time"><code class="name flex">
<span>def <span class="ident">envelop_time</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method calculating the time vector associated to a signal envelop
:return: Time vector associated to the signal envelop</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def envelop_time(self):
    &#34;&#34;&#34;
    Method calculating the time vector associated to a signal envelop
    :return: Time vector associated to the signal envelop
    &#34;&#34;&#34;
    # Get the number of frames from the signal envelop
    frames = range(len(self.envelop()))
    # Return the envelop frames computed with Librosa
    return librosa.frames_to_time(frames, hop_length=self.SP.envelop.hop_length.value)</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.fft"><code class="name flex">
<span>def <span class="ident">fft</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the Fast Fourier Transform of the signal and returns the vector.
:return: Fast Fourier Transform amplitude values in a numpy array</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fft(self):
    &#34;&#34;&#34;
    Computes the Fast Fourier Transform of the signal and returns the vector.
    :return: Fast Fourier Transform amplitude values in a numpy array
    &#34;&#34;&#34;
    fft = np.fft.fft(self.signal)
    fft = np.abs(fft[:int(len(fft) // 2)])  # Only the symmetric of the absolute value
    return fft / np.max(fft)</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.fft_bins"><code class="name flex">
<span>def <span class="ident">fft_bins</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Transforms the Fourier Transform signal into a statistic distribution.
Occurences of each frequency varies from 0 to 100 according to their
amplitude.
:return : a list containing the frequency occurences.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fft_bins(self):
    &#34;&#34;&#34;
    Transforms the Fourier Transform signal into a statistic distribution.
    Occurences of each frequency varies from 0 to 100 according to their
    amplitude.
    :return : a list containing the frequency occurences.
    &#34;&#34;&#34;

    # Make the FT values integers
    fft_integers = [int(np.around(sample * 100, 0)) for sample in self.fft()]

    # Create a list of the frequency occurrences in the signal
    occurrences = []
    for freq, count in zip(self.fft_frequencies(), fft_integers):
        occurrences.append([freq] * count)

    # flatten the list
    return [item for sublist in occurrences for item in sublist]</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.fft_frequencies"><code class="name flex">
<span>def <span class="ident">fft_frequencies</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the frequency vector associated to the Signal Fourier Transform
:return: an array containing the frequency values.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fft_frequencies(self):
    &#34;&#34;&#34;
    Computes the frequency vector associated to the Signal Fourier Transform
    :return: an array containing the frequency values.
    &#34;&#34;&#34;
    fft = self.fft()
    fft_frequencies = np.fft.fftfreq(len(fft) * 2, 1 / self.sr)  # Frequencies corresponding to the bins
    return fft_frequencies[:len(fft)]</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.filter_noise"><code class="name flex">
<span>def <span class="ident">filter_noise</span></span>(<span>self, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Method filtering the noise from the recorded signal and returning a filtered signal.
If the signal was not trimmed it is trimmed in place then filtered.
If the signal can not be trimmed it can't be filtered and the original signal is returned
:return : A Signal instance, filtered if possible.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter_noise(self, verbose=True):
    &#34;&#34;&#34;
    Method filtering the noise from the recorded signal and returning a filtered signal.
    If the signal was not trimmed it is trimmed in place then filtered.
    If the signal can not be trimmed it can&#39;t be filtered and the original signal is returned
    :return : A Signal instance, filtered if possible.
    &#34;&#34;&#34;
    try:
        return Signal(reduce_noise(audio_clip=self.signal, noise_clip=self.noise), self.sr, self.SP)
    except AttributeError:
        if self.trimmed is False:
            if verbose:
                print(&#39;Not sufficient noise in the raw signal, unable to filter.&#39;)
                print(&#39;&#39;)
            return self</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.find_onset"><code class="name flex">
<span>def <span class="ident">find_onset</span></span>(<span>self, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds the onset as an increase in more of 50% with the maximum normalized value above 0.5
:param verbose: Prints a warning if the algorithm does not converge
:return: the index of the onset in the signal</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_onset(self, verbose=True):
    &#34;&#34;&#34;
    Finds the onset as an increase in more of 50% with the maximum normalized value above 0.5
    :param verbose: Prints a warning if the algorithm does not converge
    :return: the index of the onset in the signal
    &#34;&#34;&#34;
    # Index corresponding to the onset time interval
    window_index = np.ceil(self.SP.onset.onset_time.value * self.sr).astype(int)
    # Use the normalized signal to compare against a fixed value
    onset_signal = self.normalize()
    overlap = window_index // 2  # overlap for algorithm progression
    # Initial values
    increase = 0
    i = 0
    broke = False
    while increase &lt;= 0.5:
        signal_min = np.min(np.abs(onset_signal.signal[i:i + window_index]))
        signal_max = np.max(np.abs(onset_signal.signal[i:i + window_index]))
        if (signal_max &gt; 0.5) and (signal_min != 0):
            increase = signal_max / signal_min
        else:
            increase = 0
        i += overlap
        if i + window_index &gt; len(self.signal):
            if verbose:
                print(&#39;Onset detection did not converge \n&#39;)
                print(&#39;Approximating onset with signal max value \n&#39;)
                broke = True
                break
    if broke:
        return np.argmax(self.signal)
    else:
        return np.argmax(np.abs(self.signal[i:i + window_index])) + i</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.fundamental"><code class="name flex">
<span>def <span class="ident">fundamental</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the fundamental approximated by the first peak of the fft
:return: fundamental value (Hz)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fundamental(self):
    &#34;&#34;&#34;
    Returns the fundamental approximated by the first peak of the fft
    :return: fundamental value (Hz)
    &#34;&#34;&#34;
    index = self.peaks()[0]
    fundamental = self.fft_frequencies()[index]
    return fundamental</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.listen"><code class="name flex">
<span>def <span class="ident">listen</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method to listen the sound signal in a Jupyter Notebook</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def listen(self):
    &#34;&#34;&#34;Method to listen the sound signal in a Jupyter Notebook&#34;&#34;&#34;
    file = &#39;temp.wav&#39;
    write(file, self.signal, self.sr)
    ipd.display(ipd.Audio(file))
    os.remove(file)</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.log_envelop"><code class="name flex">
<span>def <span class="ident">log_envelop</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the logarithmic scale envelop of the signal.
The width of the samples increases exponentially so that
the envelop appears having a constant window width on
an X axis logarithmic scale.
:return: The log envelop and the time vector associated in a tuple</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_envelop(self):
    &#34;&#34;&#34;
    Computes the logarithmic scale envelop of the signal.
    The width of the samples increases exponentially so that
    the envelop appears having a constant window width on
    an X axis logarithmic scale.
    :return: The log envelop and the time vector associated in a tuple
    &#34;&#34;&#34;
    if self.onset is None:
        onset = np.argmax(self.signal)
    else:
        onset = self.onset

    start_time = self.SP.log_envelop.start_time.value
    while start_time &gt; (onset / self.sr):
        start_time /= 10.

    start_exponent = int(np.log10(start_time))  # closest 10^x value for smooth graph

    if self.SP.log_envelop.min_window.value is None:
        min_window = 15 ** (start_exponent + 4)
        if min_window &lt; 15:  # Value should at least be 10
            min_window = 15
    else:
        min_window = self.SP.log_envelop.min_window.value

    # initial values
    current_exponent = start_exponent
    current_time = 10 ** current_exponent  # start time on log scale
    index = int(current_time * self.sr)  # Start at the specified time
    window = min_window  # number of samples per window
    overlap = window // 2
    log_envelop = []
    log_envelop_time = [0]  # First value for comparison

    while index + window &lt;= len(self.signal):

        while log_envelop_time[-1] &lt; 10 ** (current_exponent + 1):
            if (index + window) &lt; len(self.signal):
                log_envelop.append(np.max(self.signal[index:index + window]))
                log_envelop_time.append(self.time()[index])
                index += overlap
            else:
                break

        if window * 10 &lt; self.SP.log_envelop.max_window.value:
            window = window * 10
        else:
            window = self.SP.log_envelop.max_window.value

        overlap = window // 2
        current_exponent += 1

    # remove the value where t=0 so the log scale does not break
    log_envelop_time.remove(0)

    return np.array(log_envelop), np.array(log_envelop_time)</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.make_freq_bins"><code class="name flex">
<span>def <span class="ident">make_freq_bins</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method to divide a signal in frequency bins using butterworth filters
bins are passed as a dict, default values are :
- bass &lt; 100 Hz
- mid = 100 - 700 Hz
- highmid = 700 - 2000 Hz
- uppermid = 2000 - 4000 Hz
- presence = 4000 - 6000 Hz
- brillance &gt; 6000 Hz
:return : A dictionary with the divided signal as values and bin names as keys</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def make_freq_bins(self):
    &#34;&#34;&#34;
    Method to divide a signal in frequency bins using butterworth filters
    bins are passed as a dict, default values are :
    - bass &lt; 100 Hz
    - mid = 100 - 700 Hz
    - highmid = 700 - 2000 Hz
    - uppermid = 2000 - 4000 Hz
    - presence = 4000 - 6000 Hz
    - brillance &gt; 6000 Hz
    :return : A dictionary with the divided signal as values and bin names as keys
    &#34;&#34;&#34;

    bins = self.SP.bins.__dict__

    bass_filter = sig.butter(12, bins[&#34;bass&#34;].value, &#39;lp&#39;, fs=self.sr, output=&#39;sos&#39;)
    mid_filter = sig.butter(12, [bins[&#34;bass&#34;].value, bins[&#39;mid&#39;].value], &#39;bp&#39;, fs=self.sr, output=&#39;sos&#39;)
    himid_filter = sig.butter(12, [bins[&#34;mid&#34;].value, bins[&#39;highmid&#39;].value], &#39;bp&#39;, fs=self.sr, output=&#39;sos&#39;)
    upmid_filter = sig.butter(12, [bins[&#34;highmid&#34;].value, bins[&#39;uppermid&#39;].value], &#39;bp&#39;, fs=self.sr, output=&#39;sos&#39;)
    pres_filter = sig.butter(12, [bins[&#34;uppermid&#34;].value, bins[&#39;presence&#39;].value], &#39;bp&#39;, fs=self.sr, output=&#39;sos&#39;)
    bril_filter = sig.butter(12, bins[&#39;presence&#39;].value, &#39;hp&#39;, fs=self.sr, output=&#39;sos&#39;)

    return {
        &#34;bass&#34;: Signal(sig.sosfilt(bass_filter, self.signal), self.sr, self.SP,
                       freq_range=[0, bins[&#34;bass&#34;].value]),
        &#34;mid&#34;: Signal(sig.sosfilt(mid_filter, self.signal), self.sr, self.SP,
                      freq_range=[bins[&#34;bass&#34;].value, bins[&#34;mid&#34;].value]),
        &#34;highmid&#34;: Signal(sig.sosfilt(himid_filter, self.signal), self.sr, self.SP,
                          freq_range=[bins[&#34;mid&#34;].value, bins[&#34;highmid&#34;].value]),
        &#34;uppermid&#34;: Signal(sig.sosfilt(upmid_filter, self.signal), self.sr, self.SP,
                           freq_range=[bins[&#34;highmid&#34;].value, bins[&#34;uppermid&#34;].value]),
        &#34;presence&#34;: Signal(sig.sosfilt(pres_filter, self.signal), self.sr, self.SP,
                           freq_range=[bins[&#39;uppermid&#39;].value, bins[&#34;presence&#34;].value]),
        &#34;brillance&#34;: Signal(sig.sosfilt(bril_filter, self.signal), self.sr, self.SP,
                            freq_range=[bins[&#34;presence&#34;].value, max(self.fft_frequencies())])}</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.normalize"><code class="name flex">
<span>def <span class="ident">normalize</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Normalizes the signal to [-1, 1] and returns the normalised instance.
:return : A normalized signal</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def normalize(self):
    &#34;&#34;&#34;
    Normalizes the signal to [-1, 1] and returns the normalised instance.
    :return : A normalized signal
    &#34;&#34;&#34;
    factor = np.max(np.abs(self.signal))
    normalised_signal = Signal((self.signal / factor), self.sr, self.SP)
    normalised_signal.norm_factor = (1 / factor)
    return normalised_signal</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.peak_damping"><code class="name flex">
<span>def <span class="ident">peak_damping</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the frequency wise damping with the half bandwidth method on the Fourier Transform peaks
:return: an array containing the peak damping values</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def peak_damping(self):
    &#34;&#34;&#34;
    Computes the frequency wise damping with the half bandwidth method on the Fourier Transform peaks
    :return: an array containing the peak damping values
    &#34;&#34;&#34;
    zetas = []
    fft_freqs = self.fft_frequencies()
    fft = self.fft()[:len(fft_freqs)]
    for peak in self.peaks():
        peak_frequency = fft_freqs[peak]
        peak_height = fft[peak]
        root_height = peak_height / np.sqrt(2)
        frequency_roots = scipy.interpolate.InterpolatedUnivariateSpline(fft_freqs, fft - root_height).roots()
        sorted_roots_indexes = np.argsort(np.abs(frequency_roots - peak_frequency))
        w2, w1 = frequency_roots[sorted_roots_indexes[:2]]
        w1, w2 = np.sort([w1, w2])
        zeta = (w2 - w1) / (2 * peak_frequency)
        zetas.append(zeta)
    return np.array(zetas)</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.peaks"><code class="name flex">
<span>def <span class="ident">peaks</span></span>(<span>self, max_freq=None, height=False, result=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the harmonic peaks indexes from the FFT of the signal
:param max_freq: Supply a max frequency value overiding the one in guitarsounds_parameters
:param height: if True the height threshold is returned to be used in the 'peaks' plot
:param result: if True the Scipy peak finding results dictionary is returned
:return: peak indexes</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def peaks(self, max_freq=None, height=False, result=False):
    &#34;&#34;&#34;
    Computes the harmonic peaks indexes from the FFT of the signal
    :param max_freq: Supply a max frequency value overiding the one in guitarsounds_parameters
    :param height: if True the height threshold is returned to be used in the &#39;peaks&#39; plot
    :param result: if True the Scipy peak finding results dictionary is returned
    :return: peak indexes
    &#34;&#34;&#34;
    # Replace None by the default value
    if max_freq is None:
        max_freq = self.SP.general.fft_range.value

    # Get the fft and fft frequencies from the signal
    fft, fft_freq = self.fft(), self.fft_frequencies()

    # Find the max index
    max_index = np.where(fft_freq &gt;= max_freq)[0][0]

    # Find an approximation of the distance between peaks, this only works for harmonic signals
    peak_distance = np.argmax(fft) // 2

    # Maximum of the signal in a small region on both ends
    fft_max_start = np.max(fft[:peak_distance])
    fft_max_end = np.max(fft[max_index - peak_distance:max_index])

    # Build the curve below the peaks but above the noise
    exponents = np.linspace(np.log10(fft_max_start), np.log10(fft_max_end), max_index)
    intersect = 10 ** exponents[peak_distance]
    diff_start = fft_max_start - intersect  # offset by a small distance so that the first max is not a peak
    min_height = 10 ** np.linspace(np.log10(fft_max_start + diff_start), np.log10(fft_max_end), max_index)

    first_peak_indexes, _ = sig.find_peaks(fft[:max_index], height=min_height, distance=peak_distance)

    number_of_peaks = len(first_peak_indexes)
    if number_of_peaks &gt; 0:
        average_len = int(max_index / number_of_peaks) * 3
    else:
        average_len = int(max_index / 3)

    if average_len % 2 == 0:
        average_len += 1

    average_fft = sig.savgol_filter(fft[:max_index], average_len, 1, mode=&#39;mirror&#39;) * 1.9
    min_freq_index = np.where(fft_freq &gt;= 70)[0][0]
    average_fft[:min_freq_index] = 1

    peak_indexes, res = sig.find_peaks(fft[:max_index], height=average_fft, distance=min_freq_index)

    # Remove noisy peaks at the low frequencies
    while fft[peak_indexes[0]] &lt; 5e-2:
        peak_indexes = np.delete(peak_indexes, 0)
    while fft[peak_indexes[-1]] &lt; 1e-4:
        peak_indexes = np.delete(peak_indexes, -1)

    if not height and not result:
        return peak_indexes
    elif height:
        return peak_indexes, average_fft
    elif result:
        return peak_indexes, res
    elif height and result:
        return peak_indexes, height, res</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, kind, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>General plotting method for the Signal class, supported plots are:</p>
<p>'signal' :
Plots the time varying real signal as amplitude vs time.</p>
<p>'envelop' :
Plots the envelop of the signal as amplitude vs time.</p>
<p>'log envelop' :
Plots the envelop with logarithmic window widths on a logarithmic x axis scale.</p>
<p>'fft' :
Plots the Fourier Transform of the Signal.
If <code>ticks = 'bins'</code> is supplied in the keyword arguments, the frequency ticks are replaced
with the frequency bin values</p>
<p>'fft hist' :
Plots the octave based Fourier Transform Histogram.
Both axes are on a log scale.
If <code>ticks = 'bins'</code> is supplied in the keyword arguments, the frequency ticks are replaced
with the frequency bin values</p>
<p>'peaks' :
Plots the Fourier Transform of the Signal, with the peaks detected with the <code><a title="guitarsounds.Signal.peaks" href="#guitarsounds.Signal.peaks">Signal.peaks()</a></code> method.
If <code>peak_height = True</code> is supplied in the keyword arguments the computed height threshold is
shown on the plot.</p>
<p>'peak damping' :
Plots the frequency vs damping scatter of the damping ratio computed from the
Fourier Transform peak shapes. A polynomial curve fit is added to help visualisation.
Supported key word arguments are :
<code>n=5</code> : The order of the fitted polynomial curve, default is 5,
if the supplied value is too high, it will be reduced until the number of peaks
is sufficient to fit the polynomial.</p>
<pre><code>`inverse=True` : Default value is True, if False, the damping ratio is shown instead
of its inverse.

`normalize=False` : Default value is False, if True the damping values are normalized
from 0 to 1, to help analyze results and compare Sounds.

`ticks=None` : Default value is None, if `ticks='bins'` the x axis ticks are replaced with
frequency bin values.
</code></pre>
<p>'time damping' :
Shows the signal envelop with the fitted negative exponential curve used to determine the
time damping ratio of the signal.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self, kind, **kwargs):
    &#34;&#34;&#34;
    General plotting method for the Signal class, supported plots are:

    &#39;signal&#39; :
        Plots the time varying real signal as amplitude vs time.

    &#39;envelop&#39; :
        Plots the envelop of the signal as amplitude vs time.

    &#39;log envelop&#39; :
        Plots the envelop with logarithmic window widths on a logarithmic x axis scale.

    &#39;fft&#39; :
        Plots the Fourier Transform of the Signal.
        If `ticks = &#39;bins&#39;` is supplied in the keyword arguments, the frequency ticks are replaced
        with the frequency bin values

    &#39;fft hist&#39; :
        Plots the octave based Fourier Transform Histogram.
        Both axes are on a log scale.
        If `ticks = &#39;bins&#39;` is supplied in the keyword arguments, the frequency ticks are replaced
        with the frequency bin values

    &#39;peaks&#39; :
        Plots the Fourier Transform of the Signal, with the peaks detected with the `Signal.peaks()` method.
        If `peak_height = True` is supplied in the keyword arguments the computed height threshold is
        shown on the plot.

    &#39;peak damping&#39; :
        Plots the frequency vs damping scatter of the damping ratio computed from the
        Fourier Transform peak shapes. A polynomial curve fit is added to help visualisation.
        Supported key word arguments are :
        `n=5` : The order of the fitted polynomial curve, default is 5,
        if the supplied value is too high, it will be reduced until the number of peaks
        is sufficient to fit the polynomial.

        `inverse=True` : Default value is True, if False, the damping ratio is shown instead
        of its inverse.

        `normalize=False` : Default value is False, if True the damping values are normalized
        from 0 to 1, to help analyze results and compare Sounds.

        `ticks=None` : Default value is None, if `ticks=&#39;bins&#39;` the x axis ticks are replaced with
        frequency bin values.

    &#39;time damping&#39; :
        Shows the signal envelop with the fitted negative exponential curve used to determine the
        time damping ratio of the signal.
    &#34;&#34;&#34;
    illegal_kwargs = [&#39;max_time&#39;, &#39;n&#39;, &#39;ticks&#39;, &#39;normalize&#39;, &#39;inverse&#39;, &#39;peak_height&#39;]
    plot_kwargs = {i: kwargs[i] for i in kwargs if i not in illegal_kwargs}

    if kind == &#39;signal&#39;:

        plt.plot(self.time(), self.signal, alpha=0.6, **plot_kwargs)
        plt.xlabel(&#39;time (s)&#39;)
        plt.ylabel(&#39;amplitude&#39;)

    elif kind == &#39;envelop&#39;:

        plt.plot(self.envelop_time(), self.envelop(), **plot_kwargs)
        plt.xlabel(&#34;time (s)&#34;)
        plt.ylabel(&#34;amplitude&#34;)
        plt.grid(&#39;on&#39;)

    elif kind == &#39;log envelop&#39;:
        log_envelop, log_envelop_time = self.log_envelop()
        if (&#39;max_time&#39; in kwargs.keys()) and (kwargs[&#39;max_time&#39;] &lt; log_envelop_time[-1]):
                max_index = np.nonzero(log_envelop_time &gt;= kwargs[&#39;max_time&#39;])[0][0]
        else:
            max_index = len(log_envelop_time)

        plt.plot(log_envelop_time[:max_index], log_envelop[:max_index], **plot_kwargs)
        plt.xlabel(&#34;time (s)&#34;)
        plt.ylabel(&#34;amplitude&#34;)
        plt.xscale(&#39;log&#39;)
        plt.grid(&#39;on&#39;)

    elif kind == &#39;fft&#39;:
        # find the index corresponding to the fft range
        result = np.where(self.fft_frequencies() &gt;= self.SP.general.fft_range.value)[0]
        if len(result) == 0:
            last_index = -1
        else:
            last_index = result[0]
        plt.plot(self.fft_frequencies()[:last_index], self.fft()[:last_index], **plot_kwargs)
        plt.xlabel(&#34;frequency&#34;),
        plt.ylabel(&#34;amplitude&#34;),
        plt.yscale(&#39;log&#39;)
        plt.grid(&#39;on&#39;)

        if &#39;ticks&#39; in kwargs and kwargs[&#39;ticks&#39;] == &#39;bins&#39;:
            labels = [label for label in self.SP.bins.__dict__ if label != &#39;name&#39;]
            labels.append(&#39;brillance&#39;)
            x = [param.value for param in self.SP.bins.__dict__.values() if param != &#39;bins&#39;]
            x.append(11250)
            x_formatter = matplotlib.ticker.FixedFormatter(labels)
            x_locator = matplotlib.ticker.FixedLocator(x)
            ax = plt.gca()
            ax.xaxis.set_major_locator(x_locator)
            ax.xaxis.set_major_formatter(x_formatter)
            ax.tick_params(axis=&#34;x&#34;, labelrotation=90)

    elif kind == &#39;fft hist&#39;:
        # Histogram of frequency values occurences in octave bins
        plt.hist(self.fft_bins(), utils.octave_histogram(self.SP.general.octave_fraction.value),
                 alpha=0.7, **plot_kwargs)
        plt.xlabel(&#39;Fréquence (Hz)&#39;)
        plt.ylabel(&#39;Amplitude&#39;)
        plt.xscale(&#39;log&#39;)
        plt.yscale(&#39;log&#39;)
        plt.grid(&#39;on&#39;)

        if &#39;ticks&#39; in kwargs and kwargs[&#39;ticks&#39;] == &#39;bins&#39;:
            labels = [label for label in self.SP.bins.__dict__ if label != &#39;name&#39;]
            labels.append(&#39;brillance&#39;)
            x = [param.value for param in self.SP.bins.__dict__.values() if param != &#39;bins&#39;]
            x.append(11250)
            x_formatter = matplotlib.ticker.FixedFormatter(labels)
            x_locator = matplotlib.ticker.FixedLocator(x)
            ax = plt.gca()
            ax.xaxis.set_major_locator(x_locator)
            ax.xaxis.set_major_formatter(x_formatter)
            ax.tick_params(axis=&#34;x&#34;, labelrotation=90)

    elif kind == &#39;peaks&#39;:
        fft_freqs = self.fft_frequencies()
        fft = self.fft()
        max_index = np.where(fft_freqs &gt;= self.SP.general.fft_range.value)[0][0]
        peak_indexes, height = self.peaks(height=True)
        plt.xlabel(&#39;Fréquence (Hz)&#39;)
        plt.ylabel(&#39;Amplitude&#39;)
        plt.yscale(&#39;log&#39;)
        plt.grid(&#39;on&#39;)

        if &#39;color&#39; not in plot_kwargs.keys():
            plot_kwargs[&#39;color&#39;] = &#39;k&#39;
        plt.plot(fft_freqs[:max_index], fft[:max_index], **plot_kwargs)
        plt.scatter(fft_freqs[peak_indexes], fft[peak_indexes], color=&#39;r&#39;)
        if (&#39;peak_height&#39; in kwargs.keys()) and (kwargs[&#39;peak_height&#39;]):
            plt.plot(fft_freqs[:max_index], height, color=&#39;r&#39;)

    elif kind == &#39;peak damping&#39;:
        # Get the damping ration and peak frequencies
        if &#39;inverse&#39; in kwargs.keys() and kwargs[&#39;inverse&#39;] is False:
            zetas = np.array(self.peak_damping())
            ylabel = r&#39;Damping $\zeta$&#39;
        else:
            zetas = 1 / np.array(self.peak_damping())
            ylabel = r&#39;Inverse Damping $1/\zeta$&#39;

        peak_freqs = self.fft_frequencies()[self.peaks()]

        # If a polynomial order is supplied assign it, if not default is 5
        if &#39;n&#39; in kwargs.keys():
            n = kwargs[&#39;n&#39;]
        else:
            n = 5

        # If labels are supplied the default color are used
        if &#39;label&#39; in plot_kwargs:
            plot_kwargs[&#39;color&#39;] = None
            plot2_kwargs = plot_kwargs.copy()
            plot2_kwargs[&#39;label&#39;] = None

        # If not black and red are used
        else:
            plot_kwargs[&#39;color&#39;] = &#39;r&#39;
            plot2_kwargs = plot_kwargs.copy()
            plot2_kwargs[&#39;color&#39;] = &#39;k&#39;

        if &#39;normalize&#39; in kwargs.keys() and kwargs[&#39;normalize&#39;]:
            zetas = np.array(zetas)/np.array(zetas).max()

        plt.scatter(peak_freqs, zetas, **plot_kwargs)
        fun = utils.nth_order_polynomial_fit(n, peak_freqs, zetas)
        freq = np.linspace(peak_freqs[0], peak_freqs[-1], 100)
        plt.plot(freq, fun(freq), **plot2_kwargs)
        plt.grid(&#39;on&#39;)
        plt.title(&#39;Frequency vs Damping Factor with Order &#39; + str(n))
        plt.xlabel(&#39;Frequency (Hz)&#39;)
        plt.ylabel(ylabel)

        if &#39;ticks&#39; in kwargs and kwargs[&#39;ticks&#39;] == &#39;bins&#39;:
            labels = [label for label in self.SP.bins.__dict__ if label != &#39;name&#39;]
            labels.append(&#39;brillance&#39;)
            x = [param.value for param in self.SP.bins.__dict__.values() if param != &#39;bins&#39;]
            x.append(11250)
            x_formatter = matplotlib.ticker.FixedFormatter(labels)
            x_locator = matplotlib.ticker.FixedLocator(x)
            ax = plt.gca()
            ax.xaxis.set_major_locator(x_locator)
            ax.xaxis.set_major_formatter(x_formatter)
            ax.tick_params(axis=&#34;x&#34;, labelrotation=90)

    elif kind == &#39;time damping&#39;:
        # Get the envelop data
        envelop_time = self.normalize().envelop_time()
        envelop = self.normalize().envelop()

        # First point is the maximum because e^-kt is stricly decreasing
        first_index = np.argmax(envelop)

        # The second point is the first point where the signal crosses the lower_threshold line
        second_point_thresh = self.SP.damping.lower_threshold.value

        try:
            second_index = np.flatnonzero(envelop[first_index:] &lt;= second_point_thresh)[0]
        except IndexError:
            second_index = np.flatnonzero(envelop[first_index:] &lt;= second_point_thresh * 2)[0]

        # Function to compute the residual for the exponential curve fit
        def residual_function(zeta_w, t, s):
            return np.exp(zeta_w[0] * t) - s
        zeta_guess = [-0.5]

        result = scipy.optimize.least_squares(residual_function, zeta_guess,
                                              args=(envelop_time[first_index:second_index],
                                                    envelop[first_index:second_index]))
        # Get the zeta*omega constant
        zeta_omega = result.x[0]

        # Compute the fundamental frequency in radiants of the signal
        wd = 2 * np.pi * self.fundamental()

        plt.scatter(envelop_time[first_index], envelop[first_index], color=&#39;r&#39;)
        plt.scatter(envelop_time[second_index], envelop[second_index], color=&#39;r&#39;)
        plt.plot(envelop_time[first_index:second_index], np.exp(zeta_omega*envelop_time[first_index:second_index]),
                 c=&#39;b&#39;)
        self.normalize().plot(&#39;envelop&#39;, **plot_kwargs)
        title = &#39;Zeta : &#39; + str(np.around(-zeta_omega/wd, 5)) + &#39; Fundamental &#39; + \
                str(np.around(self.fundamental(), 0)) + &#39;Hz&#39;
        plt.title(title)</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.save_wav"><code class="name flex">
<span>def <span class="ident">save_wav</span></span>(<span>self, name, path='')</span>
</code></dt>
<dd>
<div class="desc"><p>Create a soundfile from a signal
:param name: the name of the saved file
:param path: the path were the '.wav' file is saved</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_wav(self, name, path=&#39;&#39;):
    &#34;&#34;&#34;
    Create a soundfile from a signal
    :param name: the name of the saved file
    :param path: the path were the &#39;.wav&#39; file is saved
    &#34;&#34;&#34;
    write(path + name + &#34;.wav&#34;, self.signal, self.sr)</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.time"><code class="name flex">
<span>def <span class="ident">time</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns the time vector associated to the signal
:return: numpy array corresponding to the time values of the signal samples in seconds</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def time(self):
    &#34;&#34;&#34;
    Returns the time vector associated to the signal
    :return: numpy array corresponding to the time values of the signal samples in seconds
    &#34;&#34;&#34;
    return np.arange(0, len(self.signal) * (1 / self.sr), 1 / self.sr)</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.time_damping"><code class="name flex">
<span>def <span class="ident">time_damping</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the time wise damping ratio of the signal by fitting a negative exponential curve
to the Signal envelop and computing the ratio with the Signal fundamental frequency.
:return: The damping ratio, a scalar.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def time_damping(self):
    &#34;&#34;&#34;
    Computes the time wise damping ratio of the signal by fitting a negative exponential curve
    to the Signal envelop and computing the ratio with the Signal fundamental frequency.
    :return: The damping ratio, a scalar.
    &#34;&#34;&#34;
    # Get the envelop data
    envelop_time = self.normalize().envelop_time()
    envelop = self.normalize().envelop()

    # First point is the maximum because e^-kt is stricly decreasing
    first_index = np.argmax(envelop)

    # The second point is the first point where the signal crosses the lower_threshold line
    second_point_thresh = self.SP.damping.lower_threshold.value
    try:
        second_index = np.flatnonzero(envelop[first_index:] &lt;= second_point_thresh)[0]
    except IndexError:
        second_index = np.flatnonzero(envelop[first_index:] &lt;= second_point_thresh*2)[0]

    # Function to compute the residual for the exponential curve fit
    def residual_function(zeta_w, t, s):
        &#34;&#34;&#34;
        Function computing the residual to curve fit a negative exponential to the signal envelop
        :param zeta_w: zeta*omega constant
        :param t: time vector
        :param s: signal
        :return: residual
        &#34;&#34;&#34;
        return np.exp(zeta_w[0] * t) - s

    zeta_guess = [-0.5]

    result = scipy.optimize.least_squares(residual_function, zeta_guess,
                                          args=(envelop_time[first_index:second_index],
                                                envelop[first_index:second_index]))
    # Get the zeta*omega constant
    zeta_omega = result.x[0]

    # Compute the fundamental frequency in radiants of the signal
    wd = 2 * np.pi * self.fundamental()
    return -zeta_omega / wd</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.trim_onset"><code class="name flex">
<span>def <span class="ident">trim_onset</span></span>(<span>self, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Trim the signal at the onset (max) minus the delay in milliseconds as
Specified in the SoundParameters
:param : verbose if False the warning comments are not displayed
:return : a trimmed signal with a noise attribute</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def trim_onset(self, verbose=True):
    &#34;&#34;&#34;
    Trim the signal at the onset (max) minus the delay in milliseconds as
    Specified in the SoundParameters
    :param : verbose if False the warning comments are not displayed
    :return : a trimmed signal with a noise attribute
    &#34;&#34;&#34;
    # nb of samples to keep before the onset
    delay_samples = int((self.SP.onset.onset_delay.value / 1000) * self.sr)
    onset = self.find_onset(verbose=verbose)  # find the onset

    if onset &gt; delay_samples:  # To make sure the index is positive
        trimmed_signal = Signal(self.signal[onset - delay_samples:], self.sr, self.SP)
        trimmed_signal.noise = self.signal[:onset - delay_samples]
        trimmed_signal.trimmed = True
        trimmed_signal.onset = np.argmax(trimmed_signal.signal)
        return trimmed_signal

    else:
        if verbose:
            print(&#39;Signal is too short to be trimmed before onset.&#39;)
            print(&#39;&#39;)
        self.trimmed = False
        return self</code></pre>
</details>
</dd>
<dt id="guitarsounds.Signal.trim_time"><code class="name flex">
<span>def <span class="ident">trim_time</span></span>(<span>self, time_length)</span>
</code></dt>
<dd>
<div class="desc"><p>Trims the signal to the specified length and returns a new Signal instance.
:param time_length: desired length of the new signal in seconds.
:return: A trimmed Signal</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def trim_time(self, time_length):
    &#34;&#34;&#34;
    Trims the signal to the specified length and returns a new Signal instance.
    :param time_length: desired length of the new signal in seconds.
    :return: A trimmed Signal
    &#34;&#34;&#34;
    max_index = int(time_length * self.sr)
    time_trimmed_signal = Signal(self.signal[:max_index], self.sr, self.SP)
    time_trimmed_signal.time_length = time_length
    return time_trimmed_signal</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="guitarsounds.Sound"><code class="flex name class">
<span>class <span class="ident">Sound</span></span>
<span>(</span><span>file, name='', fundamental=None, SoundParams=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A class to store audio signals obtained from a sound and compare them</p>
<p>Creates a Sound instance from a .wav file, name as a string and fundamental frequency
value can be user specified.
:param file: file path to the .wav file
:param name: Sound instance name to use in plot legend and titles
:param fundamental: Fundamental frequency value if None the value is estimated
from the FFT (see <code><a title="guitarsounds.Signal.fundamental" href="#guitarsounds.Signal.fundamental">Signal.fundamental()</a></code>).
:param SoundParams: SoundParameters to use in the Sound instance</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Sound(object):
    &#34;&#34;&#34;
    A class to store audio signals obtained from a sound and compare them
    &#34;&#34;&#34;

    def __init__(self, file, name=&#39;&#39;, fundamental=None, SoundParams=None):
        &#34;&#34;&#34;
        Creates a Sound instance from a .wav file, name as a string and fundamental frequency
        value can be user specified.
        :param file: file path to the .wav file
        :param name: Sound instance name to use in plot legend and titles
        :param fundamental: Fundamental frequency value if None the value is estimated
        from the FFT (see `Signal.fundamental`).
        :param SoundParams: SoundParameters to use in the Sound instance
        &#34;&#34;&#34;
        # create a reference of the parameters
        if SoundParams is None:
            self.SP = SP
        else:
            self.SP = SoundParams

        if type(file) == str:
            # Load the soundfile using librosa
            signal, sr = librosa.load(file)
            self.file = file

        elif type(file) == tuple:
            signal, sr = file

        # create a Signal class from the signal and sample rate
        self.raw_signal = Signal(signal, sr, self.SP)

        # Allow user specified fundamental
        self.fundamental = fundamental
        self.name = name

    def condition(self, verbose=True, return_self=False):
        &#34;&#34;&#34;
        A method conditioning the Sound instance.
        - Trimming to just before the onset
        - Filtering the noise
        :param verbose: if True problem with trimming and filtering are reported
        :param return_self: If True the method returns the conditioned Sound instance
        :return: a conditioned Sound instance if `return_self = True`
        &#34;&#34;&#34;
        self.trim_signal(verbose=verbose)
        self.filter_noise(verbose=verbose)
        self.bin_divide()
        if self.fundamental is None:
            self.fundamental = self.signal.fundamental()
        if return_self:
            return self

    def use_raw_signal(self, normalized=False):
        &#34;&#34;&#34;
        Assigns the raw signal to the `signal` attribute of the Sound instance to
        analyze it
        :param normalized: if True, the raw signal is first normalized
        :return: None
        &#34;&#34;&#34;
        if normalized:
            self.signal = self.raw_signal.normalize()
        else:
            self.signal = self.raw_signal

    def bin_divide(self):
        &#34;&#34;&#34;
        Calls the `.make_freq_bins` method of the signal to create the signals associated
        to the frequency bins. The bins are all stored in the `.bin` attribute and also as
        their names (Ex: `Sound.mid` contains the mid signal).
        :return: None
        &#34;&#34;&#34;
        &#34;&#34;&#34; a method to divide the main signal into frequency bins&#34;&#34;&#34;
        # divide in frequency bins
        self.bins = self.signal.make_freq_bins()
        # unpack the bins
        self.bass, self.mid, self.highmid, self.uppermid, self.presence, self.brillance = self.bins.values()

    def filter_noise(self, verbose=True):
        &#34;&#34;&#34;
        Filters the noise in the signal attribute
        :param verbose: if True problem are printed to the terminal
        :return: None
        &#34;&#34;&#34;
        # filter the noise in the Signal class
        self.signal = self.trimmed_signal.filter_noise(verbose=verbose)

    def trim_signal(self, verbose=True):
        &#34;&#34;&#34;
        A method to trim the signal to a specific time before the onset. The time value
        can be changed in the SoundParameters.
        :param verbose: if True problems encountered are printed to the terminal
        :return: None
        &#34;&#34;&#34;
        # Trim the signal in the signal class
        self.trimmed_signal = self.raw_signal.trim_onset(verbose=verbose)

    def validate_trim(self):
        &#34;&#34;&#34;
        Graphic validation of the `.trim_onset` method.
        Used to see if the signal onset was determined accurately
        :return: None
        &#34;&#34;&#34;
        if hasattr(self, &#39;trimmed_signal&#39;):
            fig, (ax1, ax2) = plt.subplots(2, figsize=(10, 6))
            ax1.plot(self.raw_signal.envelop_time(), self.raw_signal.envelop(), color=&#39;k&#39;)
            ax1.set(title=&#39;Old Envelop&#39;, xlabel=&#39;time&#39;, ylabel=&#39;amplitude&#39;)
            ax2.plot(self.trimmed_signal.envelop_time(), self.trimmed_signal.envelop(), color=&#39;k&#39;)
            onset_index = self.trimmed_signal.onset
            ax2.scatter(self.trimmed_signal.time()[onset_index], self.trimmed_signal.signal[onset_index], color=&#39;r&#39;)
            ax2.set(title=&#39;Trimmed signal&#39;, xlabel=&#39;time&#39;, ylabel=&#39;amplitude&#39;)
            plt.tight_layout()
        else:
            print(&#39;signal was not trimmed&#39;)

    def validate_noise(self):
        &#34;&#34;&#34;
        Audio validation of the `.filter_noise()` method.
        Allows the user to listen to the filtered and unfiltered signals
        in a jupyter notebook
        :return: None
        &#34;&#34;&#34;
        if hasattr(self, &#39;trimmed_signal&#39;):
            print(&#39;not filtered&#39;)
            self.trimmed_signal.listen()
            print(&#39;filtered&#39;)
            self.signal.listen()
        else:
            print(&#39;signal was not filtered&#39;)

    def listen_freq_bins(self):
        &#34;&#34;&#34;
        Method to listen to all the frequency bins of a sound
        in a Jupyter Notebook
        :return : None
        &#34;&#34;&#34;
        for key in self.bins.keys():
            print(key)
            self.bins[key].listen()

    def plot_freq_bins(self, bins=None):
        &#34;&#34;&#34;
        Method to plot all the frequency bins of a sound
        :param bins: frequency bins as a list to plot on the graph
        if none are specified, all the bins are plotted.
        &#34;&#34;&#34;
        if bins is None:
            bins = self.bins.keys()
        for key in bins:
            lab = key + &#39; : &#39; + str(int(self.bins[key].range[0])) + &#39; - &#39; + str(int(self.bins[key].range[1])) + &#39; Hz&#39;
            self.bins[key].plot(&#39;log envelop&#39;, label=lab)
        plt.xscale(&#39;log&#39;)
        plt.yscale(&#39;log&#39;)
        plt.legend()</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="guitarsounds.Sound.bin_divide"><code class="name flex">
<span>def <span class="ident">bin_divide</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Calls the <code>.make_freq_bins</code> method of the signal to create the signals associated
to the frequency bins. The bins are all stored in the <code>.bin</code> attribute and also as
their names (Ex: <code>Sound.mid</code> contains the mid signal).
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def bin_divide(self):
    &#34;&#34;&#34;
    Calls the `.make_freq_bins` method of the signal to create the signals associated
    to the frequency bins. The bins are all stored in the `.bin` attribute and also as
    their names (Ex: `Sound.mid` contains the mid signal).
    :return: None
    &#34;&#34;&#34;
    &#34;&#34;&#34; a method to divide the main signal into frequency bins&#34;&#34;&#34;
    # divide in frequency bins
    self.bins = self.signal.make_freq_bins()
    # unpack the bins
    self.bass, self.mid, self.highmid, self.uppermid, self.presence, self.brillance = self.bins.values()</code></pre>
</details>
</dd>
<dt id="guitarsounds.Sound.condition"><code class="name flex">
<span>def <span class="ident">condition</span></span>(<span>self, verbose=True, return_self=False)</span>
</code></dt>
<dd>
<div class="desc"><p>A method conditioning the Sound instance.
- Trimming to just before the onset
- Filtering the noise
:param verbose: if True problem with trimming and filtering are reported
:param return_self: If True the method returns the conditioned Sound instance
:return: a conditioned Sound instance if <code>return_self = True</code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def condition(self, verbose=True, return_self=False):
    &#34;&#34;&#34;
    A method conditioning the Sound instance.
    - Trimming to just before the onset
    - Filtering the noise
    :param verbose: if True problem with trimming and filtering are reported
    :param return_self: If True the method returns the conditioned Sound instance
    :return: a conditioned Sound instance if `return_self = True`
    &#34;&#34;&#34;
    self.trim_signal(verbose=verbose)
    self.filter_noise(verbose=verbose)
    self.bin_divide()
    if self.fundamental is None:
        self.fundamental = self.signal.fundamental()
    if return_self:
        return self</code></pre>
</details>
</dd>
<dt id="guitarsounds.Sound.filter_noise"><code class="name flex">
<span>def <span class="ident">filter_noise</span></span>(<span>self, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Filters the noise in the signal attribute
:param verbose: if True problem are printed to the terminal
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filter_noise(self, verbose=True):
    &#34;&#34;&#34;
    Filters the noise in the signal attribute
    :param verbose: if True problem are printed to the terminal
    :return: None
    &#34;&#34;&#34;
    # filter the noise in the Signal class
    self.signal = self.trimmed_signal.filter_noise(verbose=verbose)</code></pre>
</details>
</dd>
<dt id="guitarsounds.Sound.listen_freq_bins"><code class="name flex">
<span>def <span class="ident">listen_freq_bins</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Method to listen to all the frequency bins of a sound
in a Jupyter Notebook
:return : None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def listen_freq_bins(self):
    &#34;&#34;&#34;
    Method to listen to all the frequency bins of a sound
    in a Jupyter Notebook
    :return : None
    &#34;&#34;&#34;
    for key in self.bins.keys():
        print(key)
        self.bins[key].listen()</code></pre>
</details>
</dd>
<dt id="guitarsounds.Sound.plot_freq_bins"><code class="name flex">
<span>def <span class="ident">plot_freq_bins</span></span>(<span>self, bins=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Method to plot all the frequency bins of a sound
:param bins: frequency bins as a list to plot on the graph
if none are specified, all the bins are plotted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_freq_bins(self, bins=None):
    &#34;&#34;&#34;
    Method to plot all the frequency bins of a sound
    :param bins: frequency bins as a list to plot on the graph
    if none are specified, all the bins are plotted.
    &#34;&#34;&#34;
    if bins is None:
        bins = self.bins.keys()
    for key in bins:
        lab = key + &#39; : &#39; + str(int(self.bins[key].range[0])) + &#39; - &#39; + str(int(self.bins[key].range[1])) + &#39; Hz&#39;
        self.bins[key].plot(&#39;log envelop&#39;, label=lab)
    plt.xscale(&#39;log&#39;)
    plt.yscale(&#39;log&#39;)
    plt.legend()</code></pre>
</details>
</dd>
<dt id="guitarsounds.Sound.trim_signal"><code class="name flex">
<span>def <span class="ident">trim_signal</span></span>(<span>self, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>A method to trim the signal to a specific time before the onset. The time value
can be changed in the SoundParameters.
:param verbose: if True problems encountered are printed to the terminal
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def trim_signal(self, verbose=True):
    &#34;&#34;&#34;
    A method to trim the signal to a specific time before the onset. The time value
    can be changed in the SoundParameters.
    :param verbose: if True problems encountered are printed to the terminal
    :return: None
    &#34;&#34;&#34;
    # Trim the signal in the signal class
    self.trimmed_signal = self.raw_signal.trim_onset(verbose=verbose)</code></pre>
</details>
</dd>
<dt id="guitarsounds.Sound.use_raw_signal"><code class="name flex">
<span>def <span class="ident">use_raw_signal</span></span>(<span>self, normalized=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Assigns the raw signal to the <code>signal</code> attribute of the Sound instance to
analyze it
:param normalized: if True, the raw signal is first normalized
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def use_raw_signal(self, normalized=False):
    &#34;&#34;&#34;
    Assigns the raw signal to the `signal` attribute of the Sound instance to
    analyze it
    :param normalized: if True, the raw signal is first normalized
    :return: None
    &#34;&#34;&#34;
    if normalized:
        self.signal = self.raw_signal.normalize()
    else:
        self.signal = self.raw_signal</code></pre>
</details>
</dd>
<dt id="guitarsounds.Sound.validate_noise"><code class="name flex">
<span>def <span class="ident">validate_noise</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Audio validation of the <code>.filter_noise()</code> method.
Allows the user to listen to the filtered and unfiltered signals
in a jupyter notebook
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def validate_noise(self):
    &#34;&#34;&#34;
    Audio validation of the `.filter_noise()` method.
    Allows the user to listen to the filtered and unfiltered signals
    in a jupyter notebook
    :return: None
    &#34;&#34;&#34;
    if hasattr(self, &#39;trimmed_signal&#39;):
        print(&#39;not filtered&#39;)
        self.trimmed_signal.listen()
        print(&#39;filtered&#39;)
        self.signal.listen()
    else:
        print(&#39;signal was not filtered&#39;)</code></pre>
</details>
</dd>
<dt id="guitarsounds.Sound.validate_trim"><code class="name flex">
<span>def <span class="ident">validate_trim</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Graphic validation of the <code>.trim_onset</code> method.
Used to see if the signal onset was determined accurately
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def validate_trim(self):
    &#34;&#34;&#34;
    Graphic validation of the `.trim_onset` method.
    Used to see if the signal onset was determined accurately
    :return: None
    &#34;&#34;&#34;
    if hasattr(self, &#39;trimmed_signal&#39;):
        fig, (ax1, ax2) = plt.subplots(2, figsize=(10, 6))
        ax1.plot(self.raw_signal.envelop_time(), self.raw_signal.envelop(), color=&#39;k&#39;)
        ax1.set(title=&#39;Old Envelop&#39;, xlabel=&#39;time&#39;, ylabel=&#39;amplitude&#39;)
        ax2.plot(self.trimmed_signal.envelop_time(), self.trimmed_signal.envelop(), color=&#39;k&#39;)
        onset_index = self.trimmed_signal.onset
        ax2.scatter(self.trimmed_signal.time()[onset_index], self.trimmed_signal.signal[onset_index], color=&#39;r&#39;)
        ax2.set(title=&#39;Trimmed signal&#39;, xlabel=&#39;time&#39;, ylabel=&#39;amplitude&#39;)
        plt.tight_layout()
    else:
        print(&#39;signal was not trimmed&#39;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="guitarsounds.SoundPack"><code class="flex name class">
<span>class <span class="ident">SoundPack</span></span>
<span>(</span><span>*sounds, names=None, fundamentals=None, SoundParams=None, equalize_time=True)</span>
</code></dt>
<dd>
<div class="desc"><p>A class to store and analyse multiple sounds
Some methods are only available for the case with two sounds</p>
<p>The SoundPack can be instantiated from existing Sound class instances, either in a list or as
multiple arguments</p>
<p>The class can also handle the creation of Sound class instances if the arguments are filenames,
either a list or multiple arguments.</p>
<p>If the number of Sound contained is equal to two, the SoundPack will be 'dual' and the associated methods
will be available</p>
<p>If it contains multiple sounds the SoundPack will be multiple and a reduced number of methods will work</p>
<p>A list of names as strings and fundamental frequencies can be specified when creating the SoundPack</p>
<p>If equalize_time is set to False, the contained sounds will not be trimmed to the same length.</p>
<p>Examples :</p>
<pre><code>Sound_Test = SoundPack('sounds/test1.wav', 'sounds/test2.wav', names=['A', 'B'], fundamentals = [134, 134])

sounds = [sound1, sound2, sound3, sound4, sound5] # instances of the Sound class
large_Test = SoundPack(sounds, names=['1', '2', '3', '4', '5'])
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SoundPack(object):
    &#34;&#34;&#34;
    A class to store and analyse multiple sounds
    Some methods are only available for the case with two sounds
    &#34;&#34;&#34;

    def __init__(self, *sounds, names=None, fundamentals=None, SoundParams=None, equalize_time=True):
        &#34;&#34;&#34;
        The SoundPack can be instantiated from existing Sound class instances, either in a list or as
        multiple arguments

        The class can also handle the creation of Sound class instances if the arguments are filenames,
        either a list or multiple arguments.

        If the number of Sound contained is equal to two, the SoundPack will be &#39;dual&#39; and the associated methods
        will be available

        If it contains multiple sounds the SoundPack will be multiple and a reduced number of methods will work

        A list of names as strings and fundamental frequencies can be specified when creating the SoundPack

        If equalize_time is set to False, the contained sounds will not be trimmed to the same length.

        Examples :
        ```
        Sound_Test = SoundPack(&#39;sounds/test1.wav&#39;, &#39;sounds/test2.wav&#39;, names=[&#39;A&#39;, &#39;B&#39;], fundamentals = [134, 134])

        sounds = [sound1, sound2, sound3, sound4, sound5] # instances of the Sound class
        large_Test = SoundPack(sounds, names=[&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;, &#39;5&#39;])
        ```
        &#34;&#34;&#34;
        # create a copy of the sound parameters
        if SoundParams is None:
            self.SP = SP
        else:
            self.SP = SoundParams

        # Check if the sounds argument is a list
        if type(sounds[0]) is list:
            sounds = sounds[0]  # unpack the list

        # Check for special case
        if len(sounds) == 2:
            # special case to compare two sounds
            self.kind = &#39;dual&#39;

        elif len(sounds) &gt; 1:
            # general case for multiple sounds
            self.kind = &#39;multiple&#39;

        if type(sounds[0]) is str:
            self.sounds_from_files(sounds, names=names, fundamentals=fundamentals)

        else:
            self.sounds = sounds
            if names is None:
                names = [str(n) for n in np.arange(1, len(sounds)+1)]
                for sound, n in zip(self.sounds, names):
                    sound.name = n

        if equalize_time:
            self.equalize_time()

    def sounds_from_files(self, sound_files, names=None, fundamentals=None):
        &#34;&#34;&#34;
        Create Sound class instances and assign them to the SoundPack from a list of files
        :param sound_files: sound filenames
        :param names: sound names
        :param fundamentals: user specified fundamental frequencies
        :return: None
        &#34;&#34;&#34;
        # Make the default name list from sound filenames if none is supplied
        if (names is None) or (len(names) != len(sound_files)):
            names = [file[:-4] for file in sound_files]  # remove the .wav

        # If the fundamentals are not supplied or mismatch in number None is used
        if (fundamentals is None) or (len(fundamentals) != len(sound_files)):
            fundamentals = len(sound_files) * [None]

        # Create Sound instances from files
        self.sounds = []
        for file, name, fundamental in zip(sound_files, names, fundamentals):
            self.sounds.append(Sound(file, name=name, fundamental=fundamental,
                                     SoundParams=self.SP).condition(return_self=True))

    def equalize_time(self):
        &#34;&#34;&#34;
        Trim the sounds so that they all have the length of the shortest sound, trimming is done at the end.
        :return: None
        &#34;&#34;&#34;
        trim_index = np.min([len(sound.signal.signal) for sound in self.sounds])
        trimmed_sounds = []
        for sound in self.sounds:
            new_sound = sound
            new_sound.signal = new_sound.signal.trim_time(trim_index / sound.signal.sr)
            new_sound.bin_divide()
            trimmed_sounds.append(new_sound)
        self.sounds = trimmed_sounds

    def normalize(self):
        &#34;&#34;&#34;
        Normalize all the signals in the SoundPack and returns a normaized
        instance of itself
        :return: SoundPack with normalized signals
        &#34;&#34;&#34;
        new_sounds = []
        names = [sound.name for sound in self.sounds]
        fundamentals = [sound.fundamental for sound in self.sounds]
        for sound in self.sounds:
            sound.signal = sound.signal.normalize()
            new_sounds.append(sound)

        return SoundPack(new_sounds, names=names, fundamentals=fundamentals, SoundParams=self.SP, equalize_time=False)

    &#34;&#34;&#34;
    Methods for all SoundPacks
    &#34;&#34;&#34;

    def plot(self, kind, **kwargs):
        &#34;&#34;&#34;
        __ Multiple SoundPack Method __
        Plots a specific signal.plot for all sounds on the same figure
        Ex : compare_plot(&#39;fft&#39;) plots the fft of all sounds on a single figure
        The color argument is set to none so that the plots have different colors

        :param kind: Attribute passed to the `signal.plot()` method
        :param kwargs: key words arguments to pass to the `signal.plot()` method
        :return: None
        &#34;&#34;&#34;
        for sound in self.sounds:
            kwargs[&#39;label&#39;] = sound.name
            kwargs[&#39;color&#39;] = None
            sound.signal.plot(kind, **kwargs)

        plt.legend()

    def compare_plot(self, kind, **kwargs):
        &#34;&#34;&#34;
        __ Multiple SoundPack Method __
        Draws the same kind of plot on a different axis for each sound
        Example : `SoundPack.compare_plot(&#39;peaks&#39;)` with 4 Sounds will plot a figure with 4 axes, with each
        a different &#39;peak&#39; plot.

        :param kind: kind argument passed to `Signal.plot()`
        :param kwargs: key word arguments passed to Signal.plot()
        :return: None
        &#34;&#34;&#34;
        # if a dual SoundPack : only plot two big plots
        if self.kind == &#39;dual&#39;:
            fig, axs = plt.subplots(1, 2, figsize=(12, 6))
            for sound, ax in zip(self.sounds, axs):
                plt.sca(ax)
                kwargs[&#39;label&#39;] = sound.name
                sound.signal.plot(kind, **kwargs)

        # If a multiple SoundPack : plot on a grid of axes
        elif self.kind == &#39;multiple&#39;:

            # find the n, m values for the subplots line and columns
            n = len(self.sounds)
            if n // 4 &gt;= 10:
                # a lot of sounds
                cols = 4
            elif n // 3 &gt;= 10:
                # many sounds
                cols = 3
            elif n // 2 &lt;= 4:
                # a few sounds
                cols = 2

            remainder = n % cols
            if remainder == 0:
                rows = n // cols
            else:
                rows = n // cols + 1

            fig, axs = plt.subplots(rows, cols, figsize=(12, 4*rows))
            axs = axs.reshape(-1)
            for sound, ax in zip(self.sounds, axs):
                plt.sca(ax)
                sound.signal.plot(kind, **kwargs)
                title = ax.get_title()
                title = sound.name + &#39; &#39; + title
                ax.set_title(title)

            if remainder != 0:
                for ax in axs[-(cols - remainder):]:
                    ax.set_axis_off()

            plt.tight_layout()

    def freq_bin_plot(self, fbin=&#39;all&#39;):
        &#34;&#34;&#34;
        __ Multiple SoundPack Method __
        A function to compare signals decomposed frequency wise in the time domain on a logarithm scale.
        The methods plots all the sounds and plots their frequency bins according to the frequency bin argument fbin.

        Example : SoundPack.freq_bin_plot(fbin=&#39;mid&#39;) will plot the log-scale envelop of the &#39;mid&#39; signal of every
        sound in the SoundPack

        :param fbin: frequency bins to compare, Supported arguments are :
        &#39;all&#39;, &#39;bass&#39;, &#39;mid&#39;, &#39;highmid&#39;, &#39;uppermid&#39;, &#39;presence&#39;, &#39;brillance&#39;
        :return: None
        &#34;&#34;&#34;

        if fbin == &#39;all&#39;:
            # Create one plot per bin
            for key in [*list(self.SP.bins.__dict__.keys())[1:], &#39;brillance&#39;]:
                plt.figure(figsize=(10, 8))
                # plot every sound for a frequency bin
                norm_factors = np.array([son.bins[key].normalize().norm_factor for son in self.sounds])
                for i, son in enumerate(self.sounds):
                    lab = &#39; &#39; + key + &#39; : &#39; + str(int(son.bins[key].range[0])) + &#39; - &#39; + str(
                        int(son.bins[key].range[1])) + &#39; Hz&#39;
                    son.bins[key].normalize().plot(&#39;log envelop&#39;, label=(str(i + 1) + &#39;. &#39; + son.name + lab))
                plt.xscale(&#39;log&#39;)
                plt.legend()
                title1 = &#39;Normalisation Factor 1 : &#39; + str(np.around(norm_factors[0], 0)) + &#39;x, &#39;
                title2 = &#39;Normalisation Factor 2 : &#39; + str(np.around(norm_factors[1], 0)) + &#39;x&#39;
                plt.title(title1 + title2)

        elif fbin in [*list(SP.bins.__dict__.keys())[1:], &#39;brillance&#39;]:
            plt.figure(figsize=(10, 8))
            # Plot every envelop for a single frequency bin
            norm_factors = np.array([son.bins[fbin].normalize().norm_factor for son in self.sounds])
            for i, son in enumerate(self.sounds):
                lab = &#39; &#39; + fbin + &#39; : &#39; + str(int(son.bins[fbin].range[0])) + &#39; - &#39; + str(
                    int(son.bins[fbin].range[1])) + &#39; Hz&#39;
                son.bins[fbin].normalize().plot(&#39;log envelop&#39;, label=(str(i + 1) + &#39;. &#39; + son.name + lab))
            plt.xscale(&#39;log&#39;)
            plt.legend()
            title1 = &#39;Normalisation Factor 1 : &#39; + str(np.around(norm_factors[0], 0)) + &#39;x\n&#39;
            title2 = &#39;Normalisation Factor 2 : &#39; + str(np.around(norm_factors[1], 0)) + &#39;x&#39;
            plt.title(title1 + title2)

        else:
            print(&#39;invalid frequency bin&#39;)

    def combine_envelop(self, kind=&#39;signal&#39;, difference_factor=1, show_sounds=True, show_rejects=True, **kwargs):
        &#34;&#34;&#34;
        __ Multiple SoundPack Method __
        Combines the envelops of the Sounds contained in the SoundPack, Sounds having a too large difference factor
        from the average are rejected.

        :param kind: wich signal to use from :
        &#39;signal&#39;, &#39;bass&#39;, &#39;mid&#39;, &#39;highmid&#39;, &#39;uppermid&#39;, &#39;presence&#39;, &#39;brillance&#39;
        :param difference_factor: threshold to reject a sound from the combinaison, can be adjusted to reject
        or include more sounds.
        :param show_sounds: If True all the included Sounds are shown on the plot
        :param show_rejects: If True all the rejected Sounds are shown on the plot
        :param kwargs: Key word arguments to pass to the envelop plot.
        :return: None
        &#34;&#34;&#34;
        sounds = self.sounds
        sample_number = np.min([len(s1.signal.log_envelop()[0]) for s1 in sounds])

        if kind == &#39;signal&#39;:
            log_envelops = np.stack([s1.signal.normalize().log_envelop()[0][:sample_number] for s1 in sounds])
        elif kind in SP.bins.__dict__.keys():
            log_envelops = np.stack([s1.bins[kind].normalize().log_envelop()[0][:sample_number] for s1 in sounds])
        else:
            print(&#39;Wrong kind&#39;)

        average_log_envelop = np.mean(log_envelops, axis=0)
        means = np.tile(average_log_envelop, (len(sounds), 1))
        diffs = np.sum(np.abs(means - log_envelops), axis=1)
        diff = np.mean(diffs) * difference_factor

        good_sounds = np.array(sounds)[diffs &lt; diff]
        rejected_sounds = np.array(sounds)[diffs &gt; diff]
        average_log_envelop = np.mean(log_envelops[diffs &lt; diff], axis=0)
        norm_factors = np.array([s1.signal.normalize().norm_factor for s1 in good_sounds])

        if kind == &#39;signal&#39;:
            if show_sounds:
                for s1 in good_sounds[:-1]:
                    s1.signal.normalize().plot(kind=&#39;log envelop&#39;, alpha=0.2, color=&#39;k&#39;)
                sounds[-1].signal.normalize().plot(kind=&#39;log envelop&#39;, alpha=0.2, color=&#39;k&#39;, label=&#39;sounds&#39;)

            if show_rejects:
                if len(rejected_sounds) &gt; 1:
                    for s1 in rejected_sounds[:-1]:
                        s1.signal.normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;)
                    rejected_sounds[-1].signal.normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;,
                                                                label=&#39;rejected sounds&#39;)
                if len(rejected_sounds) == 1:
                    rejected_sounds[0].signal.normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;,
                                                               label=&#39;rejected sounds&#39;)
            if len(good_sounds) &gt; 0:
                if &#39;label&#39; in kwargs.keys():
                    plt.plot(good_sounds[0].signal.log_envelop()[1][:len(average_log_envelop)], average_log_envelop,
                             **kwargs)
                else:
                    plt.plot(good_sounds[0].signal.log_envelop()[1][:len(average_log_envelop)], average_log_envelop,
                             label=&#39;average&#39;, color=&#39;k&#39;, **kwargs)

        else:
            if show_sounds:
                for s1 in good_sounds[:-1]:
                    s1.bins[kind].normalize().plot(kind=&#39;log envelop&#39;, alpha=0.2, color=&#39;k&#39;)
                sounds[-1].bins[kind].normalize().plot(kind=&#39;log envelop&#39;, alpha=0.2, color=&#39;k&#39;, label=&#39;sounds&#39;)

            if show_rejects:
                if len(rejected_sounds) &gt; 1:
                    for s2 in rejected_sounds[:-1]:
                        s2.bins[kind].normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;)
                    rejected_sounds[-1].bins[kind].normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;,
                                                                    label=&#39;rejected sounds&#39;)
                if len(rejected_sounds) == 1:
                    rejected_sounds.bins[kind].normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;,
                                                                label=&#39;rejected sounds&#39;)

            plt.plot(good_sounds[0].signal.log_envelop()[1][:sample_number], average_log_envelop, color=&#39;k&#39;, **kwargs)

        plt.xlabel(&#39;time (s)&#39;)
        plt.ylabel(&#39;Amplitude&#39;)
        plt.legend()
        plt.xscale(&#39;log&#39;)
        print(&#39;Number of rejected sounds : &#39; + str(len(rejected_sounds)))
        print(&#39;Number of sounds included : &#39; + str(len(good_sounds)))
        print(&#39;Maximum normalisation factor : &#39; + str(np.around(np.max(norm_factors), 0)) + &#39;x&#39;)
        print(&#39;Minimum normalisation factor : &#39; + str(np.around(np.min(norm_factors), 0)) + &#39;x&#39;)

    def fundamentals(self):
        &#34;&#34;&#34;
        __ Multiple Soundpack Method __
        Displays the fundamentals of every sound in the SoundPack
        :return: None
        &#34;&#34;&#34;
        print(tabulate([[sound.name, np.around(sound.fundamental, 1)] for sound in self.sounds],
                       headers=[&#39;Name&#39;, &#39;Fundamental (Hz)&#39;]))

    &#34;&#34;&#34;
    Methods for dual SoundPacks
    &#34;&#34;&#34;

    def compare_peaks(self):
        &#34;&#34;&#34;
        __ Dual SoundPack Method __
        Compares the peaks in the Fourier Transform of two Sounds,
        the peak with the highest difference is highlighted
        :return: None
        &#34;&#34;&#34;
        if self.kind == &#39;dual&#39;:
            son1 = self.sounds[0]
            son2 = self.sounds[1]
            index1 = np.where(son1.signal.fft_frequencies() &gt; self.SP.general.fft_range.value)[0][0]
            index2 = np.where(son2.signal.fft_frequencies() &gt; self.SP.general.fft_range.value)[0][0]

            # Get the peak data from the sounds
            peaks1 = son1.signal.peaks()
            peaks2 = son2.signal.peaks()
            freq1 = son1.signal.fft_frequencies()[:index1]
            freq2 = son2.signal.fft_frequencies()[:index2]
            fft1 = son1.signal.fft()[:index1]
            fft2 = son2.signal.fft()[:index2]

            peak_distance1 = np.mean([freq1[peaks1[i]] - freq1[peaks1[i + 1]] for i in range(len(peaks1) - 1)]) / 4
            peak_distance2 = np.mean([freq2[peaks2[i]] - freq2[peaks2[i + 1]] for i in range(len(peaks2) - 1)]) / 4
            peak_distance = np.abs(np.mean([peak_distance1, peak_distance2]))

            # Align  the two peak vectors
            new_peaks1 = []
            new_peaks2 = []
            for peak1 in peaks1:
                for peak2 in peaks2:
                    if np.abs(freq1[peak1] - freq2[peak2]) &lt; peak_distance:
                        new_peaks1.append(peak1)
                        new_peaks2.append(peak2)
            new_peaks1 = np.unique(np.array(new_peaks1))
            new_peaks2 = np.unique(np.array(new_peaks2))

            different_peaks1 = []
            different_peaks2 = []
            difference_threshold = 0.5
            while len(different_peaks1) &lt; 1:
                for peak1, peak2 in zip(new_peaks1, new_peaks2):
                    if np.abs(fft1[peak1] - fft2[peak2]) &gt; difference_threshold:
                        different_peaks1.append(peak1)
                        different_peaks2.append(peak2)
                difference_threshold -= 0.01

            # Plot the output
            plt.figure(figsize=(10, 8))
            plt.yscale(&#39;symlog&#39;, linthresh=10e-1)

            # Sound 1
            plt.plot(freq1, fft1, color=&#39;#919191&#39;, label=son1.name)
            plt.scatter(freq1[new_peaks1], fft1[new_peaks1], color=&#39;b&#39;, label=&#39;peaks&#39;)
            plt.scatter(freq1[different_peaks1], fft1[different_peaks1], color=&#39;g&#39;, label=&#39;diff peaks&#39;)
            annotation_string = &#39;Peaks with &#39; + str(np.around(difference_threshold, 1)) + &#39; difference&#39;
            plt.annotate(annotation_string, (freq1[different_peaks1[0]] + peak_distance / 2, fft1[different_peaks1[0]]))

            # Sound2
            plt.plot(freq2, -fft2, color=&#39;#3d3d3d&#39;, label=son2.name)
            plt.scatter(freq2[new_peaks2], -fft2[new_peaks2], color=&#39;b&#39;)
            plt.scatter(freq2[different_peaks2], -fft2[different_peaks2], color=&#39;g&#39;)

            plt.title(&#39;Fourier Transform Peak Analysis&#39;)
            plt.legend()
        else:
            print(&#39;Unsupported for multiple sounds SoundPacks&#39;)

    def fft_mirror(self):
        &#34;&#34;&#34;
        __ Dual SoundPack Method __
        Plot the fourier transforms of two sounds on the y and -y axes to compare them.
        :return: None
        &#34;&#34;&#34;
        if self.kind == &#39;dual&#39;:
            son1 = self.sounds[0]
            son2 = self.sounds[1]
            index = np.where(son1.signal.fft_frequencies() &gt; SP.general.fft_range.value)[0][0]

            plt.figure(figsize=(10, 8))
            plt.yscale(&#39;symlog&#39;)
            plt.grid(&#39;on&#39;)
            plt.plot(son1.signal.fft_frequencies()[:index], son1.signal.fft()[:index], label=son1.name)
            plt.plot(son2.signal.fft_frequencies()[:index], -son2.signal.fft()[:index], label=son2.name)
            plt.xlabel(&#39;Fréquence (Hz)&#39;)
            plt.ylabel(&#39;Amplitude&#39;)
            plt.legend()
            plt.show()
        else:
            print(&#39;Unsupported for multiple sounds SoundPacks&#39;)

    def fft_diff(self, fraction=3, ticks=None):
        &#34;&#34;&#34;
        __ Dual SoundPack Method __
        Compare the Fourier Transform of two sounds by computing the differences of the octave bins heights.
        The two FTs are superimposed on the first plot to show differences
        The difference between the two FTs is plotted on the second plot

        :param fraction: octave fraction value used to compute the frequency bins A higher number will show
        a more precise comparison, but conclusions may be harder to draw.
        :param ticks:  If True the frequency bins intervals are used as X axis ticks
        :return: None
        &#34;&#34;&#34;
        if self.kind == &#39;dual&#39;:
            # Separate the sounds
            son1 = self.sounds[0]
            son2 = self.sounds[1]

            # Compute plotting bins
            x_values = utils.octave_values(fraction)
            hist_bins = utils.octave_histogram(fraction)
            bar_widths = np.array([hist_bins[i + 1] - hist_bins[i] for i in range(0, len(hist_bins) - 1)])

            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
            plot1 = ax1.hist(son1.signal.fft_bins(), utils.octave_histogram(fraction), color=&#39;blue&#39;, alpha=0.6,
                             label=son1.name)
            plot2 = ax1.hist(son2.signal.fft_bins(), utils.octave_histogram(fraction), color=&#39;orange&#39;, alpha=0.6,
                             label=son2.name)
            ax1.set_title(&#39;Histogramme de la FT des deux sons&#39;)
            ax1.set_xscale(&#39;log&#39;)
            ax1.set_xlabel(&#39;Fréquence (Hz)&#39;)
            ax1.set_ylabel(&#39;Amplitude&#39;)
            ax1.grid(&#39;on&#39;)
            ax1.legend()

            diff = plot1[0] - plot2[0]
            n_index = np.where(diff &lt;= 0)[0]
            p_index = np.where(diff &gt;= 0)[0]

            # Negative difference corresponding to sound 2
            ax2.bar(x_values[n_index], diff[n_index], width=bar_widths[n_index], color=&#39;orange&#39;, alpha=0.6)
            # Positive difference corresponding to sound1
            ax2.bar(x_values[p_index], diff[p_index], width=bar_widths[p_index], color=&#39;blue&#39;, alpha=0.6)
            ax2.set_title(&#39;Différence Son 1 - Son 2&#39;)
            ax2.set_xscale(&#39;log&#39;)
            ax2.set_xlabel(&#39;Fréquence (Hz)&#39;)
            ax2.set_ylabel(&#39;&lt;- Son 2 : Son 1 -&gt;&#39;)
            ax2.grid(&#39;on&#39;)

            if ticks == &#39;bins&#39;:
                labels = [label for label in self.SP.bins.__dict__ if label != &#39;name&#39;]
                labels.append(&#39;brillance&#39;)
                x = [param.value for param in self.SP.bins.__dict__.values() if param != &#39;bins&#39;]
                x.append(11250)
                x_formatter = matplotlib.ticker.FixedFormatter(labels)
                x_locator = matplotlib.ticker.FixedLocator(x)
                ax1.xaxis.set_major_locator(x_locator)
                ax1.xaxis.set_major_formatter(x_formatter)
                ax1.tick_params(axis=&#34;x&#34;, labelrotation=90)
                ax2.xaxis.set_major_locator(x_locator)
                ax2.xaxis.set_major_formatter(x_formatter)
                ax2.tick_params(axis=&#34;x&#34;, labelrotation=90)


        else:
            print(&#39;Unsupported for multiple sounds SoundPacks&#39;)

    def coherence_plot(self):
        &#34;&#34;&#34;
        __ Dual SoundPack Method __
        computes and plots the coherence between the time signal of two Sounds
        :return: None
        &#34;&#34;&#34;
        if self.kind == &#39;dual&#39;:
            f, C = sig.coherence(self.sounds[0].signal.signal, self.sounds[1].signal.signal, self.sounds[0].signal.sr)
            plt.plot(f, C, color=&#39;b&#39;)
            plt.yscale(&#39;log&#39;)
            plt.xlabel(&#39;Fréquence (Hz)&#39;)
            plt.ylabel(&#39;Coherence [0, 1]&#39;)
            title = &#39;Cohérence entre les sons &#39; + self.sounds[0].name + &#39; et &#39; + self.sounds[1].name
            plt.title(title)
        else:
            print(&#39;Unsupported for multiple sounds SoundPacks&#39;)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="guitarsounds.SoundPack.coherence_plot"><code class="name flex">
<span>def <span class="ident">coherence_plot</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Dual SoundPack Method </strong>
computes and plots the coherence between the time signal of two Sounds
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def coherence_plot(self):
    &#34;&#34;&#34;
    __ Dual SoundPack Method __
    computes and plots the coherence between the time signal of two Sounds
    :return: None
    &#34;&#34;&#34;
    if self.kind == &#39;dual&#39;:
        f, C = sig.coherence(self.sounds[0].signal.signal, self.sounds[1].signal.signal, self.sounds[0].signal.sr)
        plt.plot(f, C, color=&#39;b&#39;)
        plt.yscale(&#39;log&#39;)
        plt.xlabel(&#39;Fréquence (Hz)&#39;)
        plt.ylabel(&#39;Coherence [0, 1]&#39;)
        title = &#39;Cohérence entre les sons &#39; + self.sounds[0].name + &#39; et &#39; + self.sounds[1].name
        plt.title(title)
    else:
        print(&#39;Unsupported for multiple sounds SoundPacks&#39;)</code></pre>
</details>
</dd>
<dt id="guitarsounds.SoundPack.combine_envelop"><code class="name flex">
<span>def <span class="ident">combine_envelop</span></span>(<span>self, kind='signal', difference_factor=1, show_sounds=True, show_rejects=True, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Multiple SoundPack Method </strong>
Combines the envelops of the Sounds contained in the SoundPack, Sounds having a too large difference factor
from the average are rejected.</p>
<p>:param kind: wich signal to use from :
'signal', 'bass', 'mid', 'highmid', 'uppermid', 'presence', 'brillance'
:param difference_factor: threshold to reject a sound from the combinaison, can be adjusted to reject
or include more sounds.
:param show_sounds: If True all the included Sounds are shown on the plot
:param show_rejects: If True all the rejected Sounds are shown on the plot
:param kwargs: Key word arguments to pass to the envelop plot.
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def combine_envelop(self, kind=&#39;signal&#39;, difference_factor=1, show_sounds=True, show_rejects=True, **kwargs):
    &#34;&#34;&#34;
    __ Multiple SoundPack Method __
    Combines the envelops of the Sounds contained in the SoundPack, Sounds having a too large difference factor
    from the average are rejected.

    :param kind: wich signal to use from :
    &#39;signal&#39;, &#39;bass&#39;, &#39;mid&#39;, &#39;highmid&#39;, &#39;uppermid&#39;, &#39;presence&#39;, &#39;brillance&#39;
    :param difference_factor: threshold to reject a sound from the combinaison, can be adjusted to reject
    or include more sounds.
    :param show_sounds: If True all the included Sounds are shown on the plot
    :param show_rejects: If True all the rejected Sounds are shown on the plot
    :param kwargs: Key word arguments to pass to the envelop plot.
    :return: None
    &#34;&#34;&#34;
    sounds = self.sounds
    sample_number = np.min([len(s1.signal.log_envelop()[0]) for s1 in sounds])

    if kind == &#39;signal&#39;:
        log_envelops = np.stack([s1.signal.normalize().log_envelop()[0][:sample_number] for s1 in sounds])
    elif kind in SP.bins.__dict__.keys():
        log_envelops = np.stack([s1.bins[kind].normalize().log_envelop()[0][:sample_number] for s1 in sounds])
    else:
        print(&#39;Wrong kind&#39;)

    average_log_envelop = np.mean(log_envelops, axis=0)
    means = np.tile(average_log_envelop, (len(sounds), 1))
    diffs = np.sum(np.abs(means - log_envelops), axis=1)
    diff = np.mean(diffs) * difference_factor

    good_sounds = np.array(sounds)[diffs &lt; diff]
    rejected_sounds = np.array(sounds)[diffs &gt; diff]
    average_log_envelop = np.mean(log_envelops[diffs &lt; diff], axis=0)
    norm_factors = np.array([s1.signal.normalize().norm_factor for s1 in good_sounds])

    if kind == &#39;signal&#39;:
        if show_sounds:
            for s1 in good_sounds[:-1]:
                s1.signal.normalize().plot(kind=&#39;log envelop&#39;, alpha=0.2, color=&#39;k&#39;)
            sounds[-1].signal.normalize().plot(kind=&#39;log envelop&#39;, alpha=0.2, color=&#39;k&#39;, label=&#39;sounds&#39;)

        if show_rejects:
            if len(rejected_sounds) &gt; 1:
                for s1 in rejected_sounds[:-1]:
                    s1.signal.normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;)
                rejected_sounds[-1].signal.normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;,
                                                            label=&#39;rejected sounds&#39;)
            if len(rejected_sounds) == 1:
                rejected_sounds[0].signal.normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;,
                                                           label=&#39;rejected sounds&#39;)
        if len(good_sounds) &gt; 0:
            if &#39;label&#39; in kwargs.keys():
                plt.plot(good_sounds[0].signal.log_envelop()[1][:len(average_log_envelop)], average_log_envelop,
                         **kwargs)
            else:
                plt.plot(good_sounds[0].signal.log_envelop()[1][:len(average_log_envelop)], average_log_envelop,
                         label=&#39;average&#39;, color=&#39;k&#39;, **kwargs)

    else:
        if show_sounds:
            for s1 in good_sounds[:-1]:
                s1.bins[kind].normalize().plot(kind=&#39;log envelop&#39;, alpha=0.2, color=&#39;k&#39;)
            sounds[-1].bins[kind].normalize().plot(kind=&#39;log envelop&#39;, alpha=0.2, color=&#39;k&#39;, label=&#39;sounds&#39;)

        if show_rejects:
            if len(rejected_sounds) &gt; 1:
                for s2 in rejected_sounds[:-1]:
                    s2.bins[kind].normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;)
                rejected_sounds[-1].bins[kind].normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;,
                                                                label=&#39;rejected sounds&#39;)
            if len(rejected_sounds) == 1:
                rejected_sounds.bins[kind].normalize().plot(kind=&#39;log envelop&#39;, alpha=0.3, color=&#39;r&#39;,
                                                            label=&#39;rejected sounds&#39;)

        plt.plot(good_sounds[0].signal.log_envelop()[1][:sample_number], average_log_envelop, color=&#39;k&#39;, **kwargs)

    plt.xlabel(&#39;time (s)&#39;)
    plt.ylabel(&#39;Amplitude&#39;)
    plt.legend()
    plt.xscale(&#39;log&#39;)
    print(&#39;Number of rejected sounds : &#39; + str(len(rejected_sounds)))
    print(&#39;Number of sounds included : &#39; + str(len(good_sounds)))
    print(&#39;Maximum normalisation factor : &#39; + str(np.around(np.max(norm_factors), 0)) + &#39;x&#39;)
    print(&#39;Minimum normalisation factor : &#39; + str(np.around(np.min(norm_factors), 0)) + &#39;x&#39;)</code></pre>
</details>
</dd>
<dt id="guitarsounds.SoundPack.compare_peaks"><code class="name flex">
<span>def <span class="ident">compare_peaks</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Dual SoundPack Method </strong>
Compares the peaks in the Fourier Transform of two Sounds,
the peak with the highest difference is highlighted
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compare_peaks(self):
    &#34;&#34;&#34;
    __ Dual SoundPack Method __
    Compares the peaks in the Fourier Transform of two Sounds,
    the peak with the highest difference is highlighted
    :return: None
    &#34;&#34;&#34;
    if self.kind == &#39;dual&#39;:
        son1 = self.sounds[0]
        son2 = self.sounds[1]
        index1 = np.where(son1.signal.fft_frequencies() &gt; self.SP.general.fft_range.value)[0][0]
        index2 = np.where(son2.signal.fft_frequencies() &gt; self.SP.general.fft_range.value)[0][0]

        # Get the peak data from the sounds
        peaks1 = son1.signal.peaks()
        peaks2 = son2.signal.peaks()
        freq1 = son1.signal.fft_frequencies()[:index1]
        freq2 = son2.signal.fft_frequencies()[:index2]
        fft1 = son1.signal.fft()[:index1]
        fft2 = son2.signal.fft()[:index2]

        peak_distance1 = np.mean([freq1[peaks1[i]] - freq1[peaks1[i + 1]] for i in range(len(peaks1) - 1)]) / 4
        peak_distance2 = np.mean([freq2[peaks2[i]] - freq2[peaks2[i + 1]] for i in range(len(peaks2) - 1)]) / 4
        peak_distance = np.abs(np.mean([peak_distance1, peak_distance2]))

        # Align  the two peak vectors
        new_peaks1 = []
        new_peaks2 = []
        for peak1 in peaks1:
            for peak2 in peaks2:
                if np.abs(freq1[peak1] - freq2[peak2]) &lt; peak_distance:
                    new_peaks1.append(peak1)
                    new_peaks2.append(peak2)
        new_peaks1 = np.unique(np.array(new_peaks1))
        new_peaks2 = np.unique(np.array(new_peaks2))

        different_peaks1 = []
        different_peaks2 = []
        difference_threshold = 0.5
        while len(different_peaks1) &lt; 1:
            for peak1, peak2 in zip(new_peaks1, new_peaks2):
                if np.abs(fft1[peak1] - fft2[peak2]) &gt; difference_threshold:
                    different_peaks1.append(peak1)
                    different_peaks2.append(peak2)
            difference_threshold -= 0.01

        # Plot the output
        plt.figure(figsize=(10, 8))
        plt.yscale(&#39;symlog&#39;, linthresh=10e-1)

        # Sound 1
        plt.plot(freq1, fft1, color=&#39;#919191&#39;, label=son1.name)
        plt.scatter(freq1[new_peaks1], fft1[new_peaks1], color=&#39;b&#39;, label=&#39;peaks&#39;)
        plt.scatter(freq1[different_peaks1], fft1[different_peaks1], color=&#39;g&#39;, label=&#39;diff peaks&#39;)
        annotation_string = &#39;Peaks with &#39; + str(np.around(difference_threshold, 1)) + &#39; difference&#39;
        plt.annotate(annotation_string, (freq1[different_peaks1[0]] + peak_distance / 2, fft1[different_peaks1[0]]))

        # Sound2
        plt.plot(freq2, -fft2, color=&#39;#3d3d3d&#39;, label=son2.name)
        plt.scatter(freq2[new_peaks2], -fft2[new_peaks2], color=&#39;b&#39;)
        plt.scatter(freq2[different_peaks2], -fft2[different_peaks2], color=&#39;g&#39;)

        plt.title(&#39;Fourier Transform Peak Analysis&#39;)
        plt.legend()
    else:
        print(&#39;Unsupported for multiple sounds SoundPacks&#39;)</code></pre>
</details>
</dd>
<dt id="guitarsounds.SoundPack.compare_plot"><code class="name flex">
<span>def <span class="ident">compare_plot</span></span>(<span>self, kind, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Multiple SoundPack Method </strong>
Draws the same kind of plot on a different axis for each sound
Example : <code>SoundPack.compare_plot('peaks')</code> with 4 Sounds will plot a figure with 4 axes, with each
a different 'peak' plot.</p>
<p>:param kind: kind argument passed to <code><a title="guitarsounds.Signal.plot" href="#guitarsounds.Signal.plot">Signal.plot()</a></code>
:param kwargs: key word arguments passed to Signal.plot()
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compare_plot(self, kind, **kwargs):
    &#34;&#34;&#34;
    __ Multiple SoundPack Method __
    Draws the same kind of plot on a different axis for each sound
    Example : `SoundPack.compare_plot(&#39;peaks&#39;)` with 4 Sounds will plot a figure with 4 axes, with each
    a different &#39;peak&#39; plot.

    :param kind: kind argument passed to `Signal.plot()`
    :param kwargs: key word arguments passed to Signal.plot()
    :return: None
    &#34;&#34;&#34;
    # if a dual SoundPack : only plot two big plots
    if self.kind == &#39;dual&#39;:
        fig, axs = plt.subplots(1, 2, figsize=(12, 6))
        for sound, ax in zip(self.sounds, axs):
            plt.sca(ax)
            kwargs[&#39;label&#39;] = sound.name
            sound.signal.plot(kind, **kwargs)

    # If a multiple SoundPack : plot on a grid of axes
    elif self.kind == &#39;multiple&#39;:

        # find the n, m values for the subplots line and columns
        n = len(self.sounds)
        if n // 4 &gt;= 10:
            # a lot of sounds
            cols = 4
        elif n // 3 &gt;= 10:
            # many sounds
            cols = 3
        elif n // 2 &lt;= 4:
            # a few sounds
            cols = 2

        remainder = n % cols
        if remainder == 0:
            rows = n // cols
        else:
            rows = n // cols + 1

        fig, axs = plt.subplots(rows, cols, figsize=(12, 4*rows))
        axs = axs.reshape(-1)
        for sound, ax in zip(self.sounds, axs):
            plt.sca(ax)
            sound.signal.plot(kind, **kwargs)
            title = ax.get_title()
            title = sound.name + &#39; &#39; + title
            ax.set_title(title)

        if remainder != 0:
            for ax in axs[-(cols - remainder):]:
                ax.set_axis_off()

        plt.tight_layout()</code></pre>
</details>
</dd>
<dt id="guitarsounds.SoundPack.equalize_time"><code class="name flex">
<span>def <span class="ident">equalize_time</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Trim the sounds so that they all have the length of the shortest sound, trimming is done at the end.
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def equalize_time(self):
    &#34;&#34;&#34;
    Trim the sounds so that they all have the length of the shortest sound, trimming is done at the end.
    :return: None
    &#34;&#34;&#34;
    trim_index = np.min([len(sound.signal.signal) for sound in self.sounds])
    trimmed_sounds = []
    for sound in self.sounds:
        new_sound = sound
        new_sound.signal = new_sound.signal.trim_time(trim_index / sound.signal.sr)
        new_sound.bin_divide()
        trimmed_sounds.append(new_sound)
    self.sounds = trimmed_sounds</code></pre>
</details>
</dd>
<dt id="guitarsounds.SoundPack.fft_diff"><code class="name flex">
<span>def <span class="ident">fft_diff</span></span>(<span>self, fraction=3, ticks=None)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Dual SoundPack Method </strong>
Compare the Fourier Transform of two sounds by computing the differences of the octave bins heights.
The two FTs are superimposed on the first plot to show differences
The difference between the two FTs is plotted on the second plot</p>
<p>:param fraction: octave fraction value used to compute the frequency bins A higher number will show
a more precise comparison, but conclusions may be harder to draw.
:param ticks:
If True the frequency bins intervals are used as X axis ticks
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fft_diff(self, fraction=3, ticks=None):
    &#34;&#34;&#34;
    __ Dual SoundPack Method __
    Compare the Fourier Transform of two sounds by computing the differences of the octave bins heights.
    The two FTs are superimposed on the first plot to show differences
    The difference between the two FTs is plotted on the second plot

    :param fraction: octave fraction value used to compute the frequency bins A higher number will show
    a more precise comparison, but conclusions may be harder to draw.
    :param ticks:  If True the frequency bins intervals are used as X axis ticks
    :return: None
    &#34;&#34;&#34;
    if self.kind == &#39;dual&#39;:
        # Separate the sounds
        son1 = self.sounds[0]
        son2 = self.sounds[1]

        # Compute plotting bins
        x_values = utils.octave_values(fraction)
        hist_bins = utils.octave_histogram(fraction)
        bar_widths = np.array([hist_bins[i + 1] - hist_bins[i] for i in range(0, len(hist_bins) - 1)])

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
        plot1 = ax1.hist(son1.signal.fft_bins(), utils.octave_histogram(fraction), color=&#39;blue&#39;, alpha=0.6,
                         label=son1.name)
        plot2 = ax1.hist(son2.signal.fft_bins(), utils.octave_histogram(fraction), color=&#39;orange&#39;, alpha=0.6,
                         label=son2.name)
        ax1.set_title(&#39;Histogramme de la FT des deux sons&#39;)
        ax1.set_xscale(&#39;log&#39;)
        ax1.set_xlabel(&#39;Fréquence (Hz)&#39;)
        ax1.set_ylabel(&#39;Amplitude&#39;)
        ax1.grid(&#39;on&#39;)
        ax1.legend()

        diff = plot1[0] - plot2[0]
        n_index = np.where(diff &lt;= 0)[0]
        p_index = np.where(diff &gt;= 0)[0]

        # Negative difference corresponding to sound 2
        ax2.bar(x_values[n_index], diff[n_index], width=bar_widths[n_index], color=&#39;orange&#39;, alpha=0.6)
        # Positive difference corresponding to sound1
        ax2.bar(x_values[p_index], diff[p_index], width=bar_widths[p_index], color=&#39;blue&#39;, alpha=0.6)
        ax2.set_title(&#39;Différence Son 1 - Son 2&#39;)
        ax2.set_xscale(&#39;log&#39;)
        ax2.set_xlabel(&#39;Fréquence (Hz)&#39;)
        ax2.set_ylabel(&#39;&lt;- Son 2 : Son 1 -&gt;&#39;)
        ax2.grid(&#39;on&#39;)

        if ticks == &#39;bins&#39;:
            labels = [label for label in self.SP.bins.__dict__ if label != &#39;name&#39;]
            labels.append(&#39;brillance&#39;)
            x = [param.value for param in self.SP.bins.__dict__.values() if param != &#39;bins&#39;]
            x.append(11250)
            x_formatter = matplotlib.ticker.FixedFormatter(labels)
            x_locator = matplotlib.ticker.FixedLocator(x)
            ax1.xaxis.set_major_locator(x_locator)
            ax1.xaxis.set_major_formatter(x_formatter)
            ax1.tick_params(axis=&#34;x&#34;, labelrotation=90)
            ax2.xaxis.set_major_locator(x_locator)
            ax2.xaxis.set_major_formatter(x_formatter)
            ax2.tick_params(axis=&#34;x&#34;, labelrotation=90)


    else:
        print(&#39;Unsupported for multiple sounds SoundPacks&#39;)</code></pre>
</details>
</dd>
<dt id="guitarsounds.SoundPack.fft_mirror"><code class="name flex">
<span>def <span class="ident">fft_mirror</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Dual SoundPack Method </strong>
Plot the fourier transforms of two sounds on the y and -y axes to compare them.
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fft_mirror(self):
    &#34;&#34;&#34;
    __ Dual SoundPack Method __
    Plot the fourier transforms of two sounds on the y and -y axes to compare them.
    :return: None
    &#34;&#34;&#34;
    if self.kind == &#39;dual&#39;:
        son1 = self.sounds[0]
        son2 = self.sounds[1]
        index = np.where(son1.signal.fft_frequencies() &gt; SP.general.fft_range.value)[0][0]

        plt.figure(figsize=(10, 8))
        plt.yscale(&#39;symlog&#39;)
        plt.grid(&#39;on&#39;)
        plt.plot(son1.signal.fft_frequencies()[:index], son1.signal.fft()[:index], label=son1.name)
        plt.plot(son2.signal.fft_frequencies()[:index], -son2.signal.fft()[:index], label=son2.name)
        plt.xlabel(&#39;Fréquence (Hz)&#39;)
        plt.ylabel(&#39;Amplitude&#39;)
        plt.legend()
        plt.show()
    else:
        print(&#39;Unsupported for multiple sounds SoundPacks&#39;)</code></pre>
</details>
</dd>
<dt id="guitarsounds.SoundPack.freq_bin_plot"><code class="name flex">
<span>def <span class="ident">freq_bin_plot</span></span>(<span>self, fbin='all')</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Multiple SoundPack Method </strong>
A function to compare signals decomposed frequency wise in the time domain on a logarithm scale.
The methods plots all the sounds and plots their frequency bins according to the frequency bin argument fbin.</p>
<p>Example : SoundPack.freq_bin_plot(fbin='mid') will plot the log-scale envelop of the 'mid' signal of every
sound in the SoundPack</p>
<p>:param fbin: frequency bins to compare, Supported arguments are :
'all', 'bass', 'mid', 'highmid', 'uppermid', 'presence', 'brillance'
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def freq_bin_plot(self, fbin=&#39;all&#39;):
    &#34;&#34;&#34;
    __ Multiple SoundPack Method __
    A function to compare signals decomposed frequency wise in the time domain on a logarithm scale.
    The methods plots all the sounds and plots their frequency bins according to the frequency bin argument fbin.

    Example : SoundPack.freq_bin_plot(fbin=&#39;mid&#39;) will plot the log-scale envelop of the &#39;mid&#39; signal of every
    sound in the SoundPack

    :param fbin: frequency bins to compare, Supported arguments are :
    &#39;all&#39;, &#39;bass&#39;, &#39;mid&#39;, &#39;highmid&#39;, &#39;uppermid&#39;, &#39;presence&#39;, &#39;brillance&#39;
    :return: None
    &#34;&#34;&#34;

    if fbin == &#39;all&#39;:
        # Create one plot per bin
        for key in [*list(self.SP.bins.__dict__.keys())[1:], &#39;brillance&#39;]:
            plt.figure(figsize=(10, 8))
            # plot every sound for a frequency bin
            norm_factors = np.array([son.bins[key].normalize().norm_factor for son in self.sounds])
            for i, son in enumerate(self.sounds):
                lab = &#39; &#39; + key + &#39; : &#39; + str(int(son.bins[key].range[0])) + &#39; - &#39; + str(
                    int(son.bins[key].range[1])) + &#39; Hz&#39;
                son.bins[key].normalize().plot(&#39;log envelop&#39;, label=(str(i + 1) + &#39;. &#39; + son.name + lab))
            plt.xscale(&#39;log&#39;)
            plt.legend()
            title1 = &#39;Normalisation Factor 1 : &#39; + str(np.around(norm_factors[0], 0)) + &#39;x, &#39;
            title2 = &#39;Normalisation Factor 2 : &#39; + str(np.around(norm_factors[1], 0)) + &#39;x&#39;
            plt.title(title1 + title2)

    elif fbin in [*list(SP.bins.__dict__.keys())[1:], &#39;brillance&#39;]:
        plt.figure(figsize=(10, 8))
        # Plot every envelop for a single frequency bin
        norm_factors = np.array([son.bins[fbin].normalize().norm_factor for son in self.sounds])
        for i, son in enumerate(self.sounds):
            lab = &#39; &#39; + fbin + &#39; : &#39; + str(int(son.bins[fbin].range[0])) + &#39; - &#39; + str(
                int(son.bins[fbin].range[1])) + &#39; Hz&#39;
            son.bins[fbin].normalize().plot(&#39;log envelop&#39;, label=(str(i + 1) + &#39;. &#39; + son.name + lab))
        plt.xscale(&#39;log&#39;)
        plt.legend()
        title1 = &#39;Normalisation Factor 1 : &#39; + str(np.around(norm_factors[0], 0)) + &#39;x\n&#39;
        title2 = &#39;Normalisation Factor 2 : &#39; + str(np.around(norm_factors[1], 0)) + &#39;x&#39;
        plt.title(title1 + title2)

    else:
        print(&#39;invalid frequency bin&#39;)</code></pre>
</details>
</dd>
<dt id="guitarsounds.SoundPack.fundamentals"><code class="name flex">
<span>def <span class="ident">fundamentals</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Multiple Soundpack Method </strong>
Displays the fundamentals of every sound in the SoundPack
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fundamentals(self):
    &#34;&#34;&#34;
    __ Multiple Soundpack Method __
    Displays the fundamentals of every sound in the SoundPack
    :return: None
    &#34;&#34;&#34;
    print(tabulate([[sound.name, np.around(sound.fundamental, 1)] for sound in self.sounds],
                   headers=[&#39;Name&#39;, &#39;Fundamental (Hz)&#39;]))</code></pre>
</details>
</dd>
<dt id="guitarsounds.SoundPack.normalize"><code class="name flex">
<span>def <span class="ident">normalize</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Normalize all the signals in the SoundPack and returns a normaized
instance of itself
:return: SoundPack with normalized signals</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def normalize(self):
    &#34;&#34;&#34;
    Normalize all the signals in the SoundPack and returns a normaized
    instance of itself
    :return: SoundPack with normalized signals
    &#34;&#34;&#34;
    new_sounds = []
    names = [sound.name for sound in self.sounds]
    fundamentals = [sound.fundamental for sound in self.sounds]
    for sound in self.sounds:
        sound.signal = sound.signal.normalize()
        new_sounds.append(sound)

    return SoundPack(new_sounds, names=names, fundamentals=fundamentals, SoundParams=self.SP, equalize_time=False)</code></pre>
</details>
</dd>
<dt id="guitarsounds.SoundPack.plot"><code class="name flex">
<span>def <span class="ident">plot</span></span>(<span>self, kind, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p><strong> Multiple SoundPack Method </strong>
Plots a specific signal.plot for all sounds on the same figure
Ex : compare_plot('fft') plots the fft of all sounds on a single figure
The color argument is set to none so that the plots have different colors</p>
<p>:param kind: Attribute passed to the <code>signal.plot()</code> method
:param kwargs: key words arguments to pass to the <code>signal.plot()</code> method
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot(self, kind, **kwargs):
    &#34;&#34;&#34;
    __ Multiple SoundPack Method __
    Plots a specific signal.plot for all sounds on the same figure
    Ex : compare_plot(&#39;fft&#39;) plots the fft of all sounds on a single figure
    The color argument is set to none so that the plots have different colors

    :param kind: Attribute passed to the `signal.plot()` method
    :param kwargs: key words arguments to pass to the `signal.plot()` method
    :return: None
    &#34;&#34;&#34;
    for sound in self.sounds:
        kwargs[&#39;label&#39;] = sound.name
        kwargs[&#39;color&#39;] = None
        sound.signal.plot(kind, **kwargs)

    plt.legend()</code></pre>
</details>
</dd>
<dt id="guitarsounds.SoundPack.sounds_from_files"><code class="name flex">
<span>def <span class="ident">sounds_from_files</span></span>(<span>self, sound_files, names=None, fundamentals=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Create Sound class instances and assign them to the SoundPack from a list of files
:param sound_files: sound filenames
:param names: sound names
:param fundamentals: user specified fundamental frequencies
:return: None</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sounds_from_files(self, sound_files, names=None, fundamentals=None):
    &#34;&#34;&#34;
    Create Sound class instances and assign them to the SoundPack from a list of files
    :param sound_files: sound filenames
    :param names: sound names
    :param fundamentals: user specified fundamental frequencies
    :return: None
    &#34;&#34;&#34;
    # Make the default name list from sound filenames if none is supplied
    if (names is None) or (len(names) != len(sound_files)):
        names = [file[:-4] for file in sound_files]  # remove the .wav

    # If the fundamentals are not supplied or mismatch in number None is used
    if (fundamentals is None) or (len(fundamentals) != len(sound_files)):
        fundamentals = len(sound_files) * [None]

    # Create Sound instances from files
    self.sounds = []
    for file, name, fundamental in zip(sound_files, names, fundamentals):
        self.sounds.append(Sound(file, name=name, fundamental=fundamental,
                                 SoundParams=self.SP).condition(return_self=True))</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-variables">Global variables</a></h3>
<ul class="">
<li><code><a title="guitarsounds.SP" href="#guitarsounds.SP">SP</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="guitarsounds.Signal" href="#guitarsounds.Signal">Signal</a></code></h4>
<ul class="two-column">
<li><code><a title="guitarsounds.Signal.cavity_frequency" href="#guitarsounds.Signal.cavity_frequency">cavity_frequency</a></code></li>
<li><code><a title="guitarsounds.Signal.cavity_peak" href="#guitarsounds.Signal.cavity_peak">cavity_peak</a></code></li>
<li><code><a title="guitarsounds.Signal.envelop" href="#guitarsounds.Signal.envelop">envelop</a></code></li>
<li><code><a title="guitarsounds.Signal.envelop_time" href="#guitarsounds.Signal.envelop_time">envelop_time</a></code></li>
<li><code><a title="guitarsounds.Signal.fft" href="#guitarsounds.Signal.fft">fft</a></code></li>
<li><code><a title="guitarsounds.Signal.fft_bins" href="#guitarsounds.Signal.fft_bins">fft_bins</a></code></li>
<li><code><a title="guitarsounds.Signal.fft_frequencies" href="#guitarsounds.Signal.fft_frequencies">fft_frequencies</a></code></li>
<li><code><a title="guitarsounds.Signal.filter_noise" href="#guitarsounds.Signal.filter_noise">filter_noise</a></code></li>
<li><code><a title="guitarsounds.Signal.find_onset" href="#guitarsounds.Signal.find_onset">find_onset</a></code></li>
<li><code><a title="guitarsounds.Signal.fundamental" href="#guitarsounds.Signal.fundamental">fundamental</a></code></li>
<li><code><a title="guitarsounds.Signal.listen" href="#guitarsounds.Signal.listen">listen</a></code></li>
<li><code><a title="guitarsounds.Signal.log_envelop" href="#guitarsounds.Signal.log_envelop">log_envelop</a></code></li>
<li><code><a title="guitarsounds.Signal.make_freq_bins" href="#guitarsounds.Signal.make_freq_bins">make_freq_bins</a></code></li>
<li><code><a title="guitarsounds.Signal.normalize" href="#guitarsounds.Signal.normalize">normalize</a></code></li>
<li><code><a title="guitarsounds.Signal.peak_damping" href="#guitarsounds.Signal.peak_damping">peak_damping</a></code></li>
<li><code><a title="guitarsounds.Signal.peaks" href="#guitarsounds.Signal.peaks">peaks</a></code></li>
<li><code><a title="guitarsounds.Signal.plot" href="#guitarsounds.Signal.plot">plot</a></code></li>
<li><code><a title="guitarsounds.Signal.save_wav" href="#guitarsounds.Signal.save_wav">save_wav</a></code></li>
<li><code><a title="guitarsounds.Signal.time" href="#guitarsounds.Signal.time">time</a></code></li>
<li><code><a title="guitarsounds.Signal.time_damping" href="#guitarsounds.Signal.time_damping">time_damping</a></code></li>
<li><code><a title="guitarsounds.Signal.trim_onset" href="#guitarsounds.Signal.trim_onset">trim_onset</a></code></li>
<li><code><a title="guitarsounds.Signal.trim_time" href="#guitarsounds.Signal.trim_time">trim_time</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="guitarsounds.Sound" href="#guitarsounds.Sound">Sound</a></code></h4>
<ul class="two-column">
<li><code><a title="guitarsounds.Sound.bin_divide" href="#guitarsounds.Sound.bin_divide">bin_divide</a></code></li>
<li><code><a title="guitarsounds.Sound.condition" href="#guitarsounds.Sound.condition">condition</a></code></li>
<li><code><a title="guitarsounds.Sound.filter_noise" href="#guitarsounds.Sound.filter_noise">filter_noise</a></code></li>
<li><code><a title="guitarsounds.Sound.listen_freq_bins" href="#guitarsounds.Sound.listen_freq_bins">listen_freq_bins</a></code></li>
<li><code><a title="guitarsounds.Sound.plot_freq_bins" href="#guitarsounds.Sound.plot_freq_bins">plot_freq_bins</a></code></li>
<li><code><a title="guitarsounds.Sound.trim_signal" href="#guitarsounds.Sound.trim_signal">trim_signal</a></code></li>
<li><code><a title="guitarsounds.Sound.use_raw_signal" href="#guitarsounds.Sound.use_raw_signal">use_raw_signal</a></code></li>
<li><code><a title="guitarsounds.Sound.validate_noise" href="#guitarsounds.Sound.validate_noise">validate_noise</a></code></li>
<li><code><a title="guitarsounds.Sound.validate_trim" href="#guitarsounds.Sound.validate_trim">validate_trim</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="guitarsounds.SoundPack" href="#guitarsounds.SoundPack">SoundPack</a></code></h4>
<ul class="two-column">
<li><code><a title="guitarsounds.SoundPack.coherence_plot" href="#guitarsounds.SoundPack.coherence_plot">coherence_plot</a></code></li>
<li><code><a title="guitarsounds.SoundPack.combine_envelop" href="#guitarsounds.SoundPack.combine_envelop">combine_envelop</a></code></li>
<li><code><a title="guitarsounds.SoundPack.compare_peaks" href="#guitarsounds.SoundPack.compare_peaks">compare_peaks</a></code></li>
<li><code><a title="guitarsounds.SoundPack.compare_plot" href="#guitarsounds.SoundPack.compare_plot">compare_plot</a></code></li>
<li><code><a title="guitarsounds.SoundPack.equalize_time" href="#guitarsounds.SoundPack.equalize_time">equalize_time</a></code></li>
<li><code><a title="guitarsounds.SoundPack.fft_diff" href="#guitarsounds.SoundPack.fft_diff">fft_diff</a></code></li>
<li><code><a title="guitarsounds.SoundPack.fft_mirror" href="#guitarsounds.SoundPack.fft_mirror">fft_mirror</a></code></li>
<li><code><a title="guitarsounds.SoundPack.freq_bin_plot" href="#guitarsounds.SoundPack.freq_bin_plot">freq_bin_plot</a></code></li>
<li><code><a title="guitarsounds.SoundPack.fundamentals" href="#guitarsounds.SoundPack.fundamentals">fundamentals</a></code></li>
<li><code><a title="guitarsounds.SoundPack.normalize" href="#guitarsounds.SoundPack.normalize">normalize</a></code></li>
<li><code><a title="guitarsounds.SoundPack.plot" href="#guitarsounds.SoundPack.plot">plot</a></code></li>
<li><code><a title="guitarsounds.SoundPack.sounds_from_files" href="#guitarsounds.SoundPack.sounds_from_files">sounds_from_files</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>